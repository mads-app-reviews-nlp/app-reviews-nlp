# -*- coding: utf-8 -*-
"""Google Play Scraper.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10R6EIy6fwvM6HFXQaOqc4CzS2nGMn1lK

# Create a Dataset for Sentiment Analysis

## Setup

Let's install the required packages and setup the imports:
"""

#!pip install -qq google-play-scraper
#!pip install -qq -U watermark

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext watermark
# %watermark -v -p pandas,matplotlib,seaborn,google_play_scraper

# Commented out IPython magic to ensure Python compatibility.

import json
import pandas as pd
from tqdm import tqdm

import seaborn as sns
import matplotlib.pyplot as plt

from pygments import highlight
from pygments.lexers import JsonLexer
from pygments.formatters import TerminalFormatter

from google_play_scraper import Sort, reviews, app

# %matplotlib inline
# %config InlineBackend.figure_format='retina'

sns.set(style='whitegrid', palette='muted', font_scale=1.2)

"""## The Goal of the Dataset

You want to get feedback for your app. Both negative and positive are good. But the negative one can reveal critical features that are missing or downtime of your service (when it is much more frequent).

Lucky for us, Google Play has plenty of apps, reviews, and scores. We can scrape app info and reviews using the [google-play-scraper](https://github.com/JoMingyu/google-play-scraper) package.

"""

app_packages = [
  'com.global.foodpanda.android',
  'com.grabtaxi.passenger',
  'com.deliveroo.orderapp'
]

"""## Scraping App Information

Let's scrape the info for each app:
"""

app_infos = []

for ap in tqdm(app_packages):
  info = app(ap, lang='en', country='sg')
  del info['comments']
  app_infos.append(info)

"""We got the info for all 15 apps. Let's write a helper function that prints JSON objects a bit better:"""

def print_json(json_object):
  json_str = json.dumps(
    json_object, 
    indent=2, 
    sort_keys=True, 
    default=str
  )
  print(highlight(json_str, JsonLexer(), TerminalFormatter()))

"""Here is a sample app information from the list:"""

print_json(app_infos[0])

"""This contains lots of information including the number of ratings, number of reviews and number of ratings for each score (1 to 5). Let's ignore all of that and have a look at their beautiful icons:"""

def format_title(title):
  sep_index = title.find(':') if title.find(':') != -1 else title.find('-')
  if sep_index != -1:
    title = title[:sep_index]
  return title[:10]

fig, axs = plt.subplots(2, len(app_infos) // 2, figsize=(14, 5))

for i, ax in enumerate(axs.flat):
  ai = app_infos[i]
  img = plt.imread(ai['icon'])
  ax.imshow(img)
  ax.set_title(format_title(ai['title']))
  ax.axis('off')

"""We'll store the app information for later by converting the JSON objects into a Pandas dataframe and saving the result into a CSV file:"""

app_infos_df = pd.DataFrame(app_infos)
app_infos_df.to_csv('apps.csv', index=None, header=True)

app_infos_df.head()

"""## Scraping App Reviews

In an ideal world, we would get all the reviews. But there are lots of them and we're scraping the data. That wouldn't be very polite. What should we do?

We want:

- Balanced dataset - roughly the same number of reviews for each score (1-5)
- A representative sample of the reviews for each app

We can satisfy the first requirement by using the scraping package option to filter the review score. For the second, we'll sort the reviews by their helpfulness, which are the reviews that Google Play thinks are most important. Just in case, we'll get a subset from the newest, too:
"""

app_reviews = []

for ap in tqdm(app_packages):
  for score in list(range(1, 6)):
    for sort_order in [Sort.MOST_RELEVANT, Sort.NEWEST]:
      rvs, _ = reviews(
        ap,
        lang='en',
        country='sg',
        sort=sort_order,
        count= 200 if score == 3 else 100,
        filter_score_with=score
      )
      for r in rvs:
        r['sortOrder'] = 'most_relevant' if sort_order == Sort.MOST_RELEVANT else 'newest'
        r['appId'] = ap
      app_reviews.extend(rvs)

"""Note that we're adding the app id and sort order to each review. Here's an example for one:"""

print_json(app_reviews[0])

"""`repliedAt` and `replyContent` contain the developer response to the review. Of course, they can be missing.

How many app reviews did we get?


"""

len(app_reviews)

"""Let's save the reviews to a CSV file:"""

app_reviews_df = pd.DataFrame(app_reviews)
app_reviews_df.to_csv('reviews.csv', index=None, header=True)

app_reviews_df.head()

"""## References

- [Google Play Scraper for Python](https://github.com/JoMingyu/google-play-scraper)
"""