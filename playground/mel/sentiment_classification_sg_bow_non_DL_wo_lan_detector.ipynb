{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21330d8",
   "metadata": {},
   "source": [
    "## Sentiment Classification SG Reviews Data (BOW, non-Deep Learning) - No Language Detector\n",
    "\n",
    "This notebook covers two good approaches to perform sentiment classification - Naive Bayes and Logistic Regression. We will train SG reviews data on both.\n",
    "\n",
    "As a rule of thumb, reviews that are 3 stars and above are **positive**, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd1171c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /home/meln/.local/lib/python3.8/site-packages (3.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (0.7.5)\n",
      "Requirement already satisfied: jinja2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy) (4.59.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: setuptools in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/meln/.local/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a09b873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /home/meln/.local/lib/python3.8/site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/meln/.local/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b213884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy_langdetect in /home/meln/.local/lib/python3.8/site-packages (0.1.2)\n",
      "Requirement already satisfied: pytest in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy_langdetect) (6.2.3)\n",
      "Requirement already satisfied: langdetect==1.0.7 in /home/meln/.local/lib/python3.8/site-packages (from spacy_langdetect) (1.0.7)\n",
      "Requirement already satisfied: six in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from langdetect==1.0.7->spacy_langdetect) (1.15.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pytest->spacy_langdetect) (20.3.0)\n",
      "Requirement already satisfied: iniconfig in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pytest->spacy_langdetect) (1.1.1)\n",
      "Requirement already satisfied: packaging in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pytest->spacy_langdetect) (20.9)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pytest->spacy_langdetect) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pytest->spacy_langdetect) (1.10.0)\n",
      "Requirement already satisfied: toml in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pytest->spacy_langdetect) (0.10.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from packaging->pytest->spacy_langdetect) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy_langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad89d88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 13.9 MB 17.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/meln/.local/lib/python3.8/site-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (20.9)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: setuptools in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.59.0)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.1)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/meln/.local/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.1.1)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "926204c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import spacy\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from spacy.language import Language\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22215586",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1fcb6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>Used to be a good app been using for years, no...</td>\n",
       "      <td>5</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>Grab app is convenient because you can use mul...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>I used to love the subscription plans that the...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-06</td>\n",
       "      <td>I ordered a grabfood and one of the 3 items ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-26</td>\n",
       "      <td>This platform gives too much power to restaura...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             review  rating  \\\n",
       "0  2020-09-30  Used to be a good app been using for years, no...       5   \n",
       "1  2020-08-21  Grab app is convenient because you can use mul...       1   \n",
       "2  2020-11-18  I used to love the subscription plans that the...       1   \n",
       "3  2021-11-06  I ordered a grabfood and one of the 3 items ar...       1   \n",
       "4  2021-09-26  This platform gives too much power to restaura...       1   \n",
       "\n",
       "        app  \n",
       "0  GrabFood  \n",
       "1  GrabFood  \n",
       "2  GrabFood  \n",
       "3  GrabFood  \n",
       "4  GrabFood  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sg = pd.read_pickle(\"assets/sg_reviews.pkl\")\n",
    "reviews_sg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49be95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_sg['label'] = np.where(reviews_sg['rating'] >= 3, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "570595bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>app</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>Used to be a good app been using for years, no...</td>\n",
       "      <td>5</td>\n",
       "      <td>GrabFood</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>Grab app is convenient because you can use mul...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>I used to love the subscription plans that the...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-06</td>\n",
       "      <td>I ordered a grabfood and one of the 3 items ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-26</td>\n",
       "      <td>This platform gives too much power to restaura...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             review  rating  \\\n",
       "0  2020-09-30  Used to be a good app been using for years, no...       5   \n",
       "1  2020-08-21  Grab app is convenient because you can use mul...       1   \n",
       "2  2020-11-18  I used to love the subscription plans that the...       1   \n",
       "3  2021-11-06  I ordered a grabfood and one of the 3 items ar...       1   \n",
       "4  2021-09-26  This platform gives too much power to restaura...       1   \n",
       "\n",
       "        app  label  \n",
       "0  GrabFood      0  \n",
       "1  GrabFood      1  \n",
       "2  GrabFood      1  \n",
       "3  GrabFood      1  \n",
       "4  GrabFood      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae770f7",
   "metadata": {},
   "source": [
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f956a36",
   "metadata": {},
   "source": [
    "Check the dataset size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9a3f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659684\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_sg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e629cae",
   "metadata": {},
   "source": [
    "And the type of apps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64d82e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GrabFood', 'Deliveroo', 'FoodPanda']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_list = list(reviews_sg['app'].unique())\n",
    "app_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1180a133",
   "metadata": {},
   "source": [
    "Let's also get a sense of our dataset's balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fd33ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.740038\n",
       "1    0.259962\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sg['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1feda2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.749\n",
      "1    0.251\n",
      "Name: label, dtype: float64\n",
      "0    0.658943\n",
      "1    0.341057\n",
      "Name: label, dtype: float64\n",
      "0    0.747103\n",
      "1    0.252897\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# By app\n",
    "\n",
    "for app in app_list:\n",
    "    print(reviews_sg[reviews_sg['app'] == app]['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a556a3",
   "metadata": {},
   "source": [
    "Across the board the distribution of positive and negative reviews are quite consistent between the apps. Overall, there's an imbalance in our dataset, with positive reviews making for 75% of the dataset. Let's also check for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd9c2c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       0\n",
       "review    87\n",
       "rating     0\n",
       "app        0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sg.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb8b89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_sg = reviews_sg.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2701e569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Used to be a good app been using for years, no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grab app is convenient because you can use mul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I used to love the subscription plans that the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I ordered a grabfood and one of the 3 items ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This platform gives too much power to restaura...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  Used to be a good app been using for years, no...      0\n",
       "1  Grab app is convenient because you can use mul...      1\n",
       "2  I used to love the subscription plans that the...      1\n",
       "3  I ordered a grabfood and one of the 3 items ar...      1\n",
       "4  This platform gives too much power to restaura...      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc = reviews_sg.copy()\n",
    "df_proc.drop(columns=['date', 'rating', 'app'], inplace=True)\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea35db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_proc['review']\n",
    "y = df_proc['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e23ba",
   "metadata": {},
   "source": [
    "We will split the dataset into `train`, `test`, and `dev`, with 80%, 10%, 10% ratio, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "001cc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_test, X_dev, y_test, y_dev = train_test_split(X_test, y_test, test_size=0.5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "676ca2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527677"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b338cf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65960"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e946dbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65960"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acc8ec94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sukish'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c23ad78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'💚'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70a46a",
   "metadata": {},
   "source": [
    "## 2. Bag-of-Words Approach on Naive Bayes & Logistic Regression\n",
    "\n",
    "This section explores the use of bag of words as feature extraction. But first, let's have a look at the token frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2550abec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 527677/527677 [00:14<00:00, 35550.28it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fill this with any token (with anything in it!) for tokens separated by whitespace\n",
    "ws_tokens = Counter()\n",
    "\n",
    "# Fill this one with tokens separated by whitespace but constisting only of tokens\n",
    "# that are totally made of alphanumeric characters (you can use the \\w character\n",
    "# class in making the regex)\n",
    "\n",
    "alpha_ws_tokens = Counter()\n",
    "\n",
    "# Fill this one with the tokens separated by *word boundaries* (not white space) that consist\n",
    "# of alphanumeric characters (use \\w again)\n",
    "alpha_re_tokens = Counter()\n",
    "for review in tqdm(X_train):\n",
    "    ws_review = review.split()\n",
    "    ws_tokens.update(ws_review)\n",
    "    # Note: use fullmatch() as it anchor both the start and end of str. match() won't work.\n",
    "    alpha_ws_tokens.update([re.fullmatch(r'\\w+', word).group() for word in ws_review if re.fullmatch(r'\\w+', word) != None])\n",
    "    alpha_re_tokens.update(re.findall(r'\\w+', review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5196b087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "257197\n",
      "109083\n",
      "137382\n"
     ]
    }
   ],
   "source": [
    "print(len(ws_tokens))\n",
    "print(len(alpha_ws_tokens))\n",
    "print(len(alpha_re_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "84d1db31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 147081),\n",
       " ('to', 139697),\n",
       " ('and', 113582),\n",
       " ('app', 102748),\n",
       " ('I', 99338),\n",
       " ('is', 75412),\n",
       " ('it', 70300),\n",
       " ('Good', 65707),\n",
       " ('order', 59305),\n",
       " ('a', 58797),\n",
       " ('for', 58218),\n",
       " ('food', 56091),\n",
       " ('my', 54214),\n",
       " ('good', 54179),\n",
       " ('service', 46719),\n",
       " ('of', 44700),\n",
       " ('t', 40529),\n",
       " ('in', 40378),\n",
       " ('not', 39781),\n",
       " ('delivery', 38293),\n",
       " ('this', 36684),\n",
       " ('but', 36672),\n",
       " ('you', 35021),\n",
       " ('time', 31714),\n",
       " ('i', 30103),\n",
       " ('on', 28657),\n",
       " ('that', 28267),\n",
       " ('use', 27340),\n",
       " ('have', 26611),\n",
       " ('they', 26187),\n",
       " ('Very', 25966),\n",
       " ('with', 25488),\n",
       " ('s', 25123),\n",
       " ('very', 24833),\n",
       " ('me', 24782),\n",
       " ('was', 24579),\n",
       " ('can', 22862),\n",
       " ('are', 22818),\n",
       " ('so', 22034),\n",
       " ('from', 19347),\n",
       " ('no', 19344),\n",
       " ('be', 19055),\n",
       " ('Nice', 18961),\n",
       " ('your', 18942),\n",
       " ('It', 18842),\n",
       " ('The', 18170),\n",
       " ('when', 17514),\n",
       " ('Great', 17360),\n",
       " ('at', 15795),\n",
       " ('customer', 15624),\n",
       " ('more', 14613),\n",
       " ('up', 14299),\n",
       " ('or', 14169),\n",
       " ('get', 13762),\n",
       " ('just', 13748),\n",
       " ('apps', 13612),\n",
       " ('as', 13532),\n",
       " ('easy', 13368),\n",
       " ('all', 13244),\n",
       " ('even', 13077),\n",
       " ('like', 13066),\n",
       " ('will', 12820),\n",
       " ('an', 12730),\n",
       " ('if', 12691),\n",
       " ('grab', 12597),\n",
       " ('restaurant', 12341),\n",
       " ('after', 11466),\n",
       " ('experience', 11379),\n",
       " ('bad', 11289),\n",
       " ('great', 11225),\n",
       " ('nice', 11178),\n",
       " ('driver', 11118),\n",
       " ('there', 10993),\n",
       " ('panda', 10581),\n",
       " ('Excellent', 10240),\n",
       " ('always', 10069),\n",
       " ('This', 9865),\n",
       " ('foodpanda', 9686),\n",
       " ('restaurants', 9572),\n",
       " ('now', 9388),\n",
       " ('than', 9369),\n",
       " ('update', 9338),\n",
       " ('Easy', 9293),\n",
       " ('payment', 9274),\n",
       " ('don', 9222),\n",
       " ('only', 9194),\n",
       " ('one', 8951),\n",
       " ('love', 8877),\n",
       " ('Best', 8755),\n",
       " ('has', 8524),\n",
       " ('their', 8496),\n",
       " ('2', 8468),\n",
       " ('rider', 8375),\n",
       " ('cancel', 8357),\n",
       " ('been', 8339),\n",
       " ('best', 8281),\n",
       " ('we', 8279),\n",
       " ('App', 8201),\n",
       " ('any', 8134),\n",
       " ('still', 8126)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100 = alpha_re_tokens.most_common(100)\n",
    "top_100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc95113",
   "metadata": {},
   "source": [
    "Lots of stopwords, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7e6f87cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(100))\n",
    "y = [word_tup[1] for word_tup in top_100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "488d0ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAbxElEQVR4nO3df2xd5Z3n8ffHNqGhbagJgYY4P8gmyyxB2219lXo6oxFdZkhmBjVoBapXVGSnQdGiqEOnU7VkKsEs1axAMypTOoAUAUNgUiAK7CaqNtNmA6OOVnHAppoNIWWxEpK4ZEhIXAZtVySOv/vHfW5zfHN9bN9r+9r3fl6S5XO/5zwnzwOJv35+nOcoIjAzMxtNS70rYGZmM5sThZmZ5XKiMDOzXE4UZmaWy4nCzMxytdW7ApPtyiuvjGXLltW7GmZms0pfX9/7EbGg0rmGSxTLli2jt7e33tUwM5tVJB0d7ZyHnszMLJcThZmZ5XKiMDOzXE4UZmaWy4nCzMxyOVGYmVkuJ4qMvqODPPpKP31HB+tdFTOzGaPhnqOoVt/RQe54ooezQ8PMaWth211ddC5tr3e1zMzqzj2KpOfwac4ODTMccG5omJ7Dp+tdJTOzGcGJIulaPp85bS20Ci5pa6Fr+fx6V8nMbEbw0FPSubSdbXd10XP4NF3L53vYycwscaLI6Fza7gRhZlbGQ09mZpbLicLMzHI5UZiZWa4xE4WkpySdlPRGhXPflBSSrszENkvql/SWpDWZeKekA+ncI5KU4pdKeiHF90talimzXtLb6Wt9za01M7MJG0+P4mlgbXlQ0mLg94Bjmdj1QDewKpV5TFJrOv04sBFYmb5K99wADEbECuBh4KF0ryuA+4HPA6uB+yV5ptnMbJqNmSgi4qfAmQqnHga+BUQmtg54PiI+iogjQD+wWtJCYF5E7IuIAJ4Bbs2U2ZqOdwA3pd7GGmBPRJyJiEFgDxUS1lTxdh5mZkVVLY+V9CXgFxHxT2kEqWQR0JP5PJBi59JxebxU5jhARAxJ+gCYn41XKFNen40UeyssWbKkmiaN4O08zMwumPBktqTLgO8A91U6XSEWOfFqy4wMRmyJiEJEFBYsqPhu8Anxdh5mZhdUs+rpXwHXAv8k6R2gA3hd0qcp/ta/OHNtB/BuindUiJMtI6kNuJziUNdo95py3s7DzOyCCQ89RcQB4KrS55QsChHxvqRdwA8lfQ+4huKk9asRcV7Sh5K6gP3AncAP0i12AeuBfcBtwMsREZJ+DPzXzAT2zcDmaho5Ud7Ow8zsgjEThaTngBuBKyUNAPdHxJOVro2Ig5K2A28CQ8CmiDifTt9NcQXVXGB3+gJ4EnhWUj/FnkR3utcZSd8FXkvXPRARlSbVp4S38zAzK1JxEVLjKBQK0dvbW+9qmJnNKpL6IqJQ6ZyfzDYzs1xOFGZmlsuJwszMcjlRmJlZLicKMzPL5URhZma5nCjMzCyXE4WZmeVyojAzs1xOFGZmlsuJwszMcjlRmJlZLicKMzPL5URhZma5nCjMzCyXE4WZmeVyojAzs1xOFGZmlsuJwszMcjlRmJlZrjEThaSnJJ2U9EYm9peSfi7pf0v6b5I+lTm3WVK/pLckrcnEOyUdSOcekaQUv1TSCym+X9KyTJn1kt5OX+snq9FmZjZ+4+lRPA2sLYvtAW6IiH8L/B9gM4Ck64FuYFUq85ik1lTmcWAjsDJ9le65ARiMiBXAw8BD6V5XAPcDnwdWA/dLap94E83MrBZjJoqI+Clwpiz2k4gYSh97gI50vA54PiI+iogjQD+wWtJCYF5E7IuIAJ4Bbs2U2ZqOdwA3pd7GGmBPRJyJiEGKyak8YZmZ2RSbjDmKrwK70/Ei4Hjm3ECKLUrH5fERZVLy+QCYn3Ovi0jaKKlXUu+pU6dqaoyZmY1UU6KQ9B1gCNhWClW4LHLi1ZYZGYzYEhGFiCgsWLAgv9JmZjYhVSeKNLl8C3BHGk6C4m/9izOXdQDvpnhHhfiIMpLagMspDnWNdi8zM5tGVSUKSWuBbwNfiohfZU7tArrTSqZrKU5avxoRJ4APJXWl+Yc7gZ2ZMqUVTbcBL6fE82PgZkntaRL75hQzM7Np1DbWBZKeA24ErpQ0QHEl0mbgUmBPWuXaExH/OSIOStoOvElxSGpTRJxPt7qb4gqquRTnNErzGk8Cz0rqp9iT6AaIiDOSvgu8lq57ICJGTKqbmdnU04VRo8ZQKBSit7e33tUwM5tVJPVFRKHSOT+ZbWZmuZwoxqHv6CCPvtJP39HBelfFzGzajTlH0ez6jg5yxxM9nB0aZk5bC9vu6qJzqR8QN7Pm4R7FGHoOn+bs0DDDAeeGhuk5fLreVTIzm1ZOFGPoWj6fOW0ttAouaWuha/n8elfJzGxaeehpDJ1L29l2Vxc9h0/TtXy+h53MrOk4UYxD59J2Jwgza1oeejIzs1xOFGZmlsuJwszMcjlRmJlZLicKMzPL5URhZma5nCjMzCyXE4WZmeVyojAzs1xOFBPkLcfNrNl4C48J8JbjZtaM3KOYAG85bmbNaMxEIekpSSclvZGJXSFpj6S30/f2zLnNkvolvSVpTSbeKelAOveIJKX4pZJeSPH9kpZlyqxPf8bbktZPWqur5C3HzawZjadH8TSwtix2L7A3IlYCe9NnJF0PdAOrUpnHJLWmMo8DG4GV6at0zw3AYESsAB4GHkr3ugK4H/g8sBq4P5uQ6qG05fg3br7Ow05m1jTGTBQR8VPgTFl4HbA1HW8Fbs3En4+IjyLiCNAPrJa0EJgXEfsiIoBnysqU7rUDuCn1NtYAeyLiTEQMAnu4OGFNu86l7Wz64go6l7Z7YtvMmkK1k9lXR8QJgIg4IemqFF8E9GSuG0ixc+m4PF4qczzda0jSB8D8bLxCmREkbaTYW2HJkiVVNmliPLFtZs1isiezVSEWOfFqy4wMRmyJiEJEFBYsWDCuitbKE9tm1iyqTRTvpeEk0veTKT4ALM5c1wG8m+IdFeIjykhqAy6nONQ12r1mBE9sm1mzqDZR7AJKq5DWAzsz8e60kulaipPWr6Zhqg8ldaX5hzvLypTudRvwcprH+DFws6T2NIl9c4rNCJ7YNrNmMeYchaTngBuBKyUNUFyJ9CCwXdIG4BhwO0BEHJS0HXgTGAI2RcT5dKu7Ka6gmgvsTl8ATwLPSuqn2JPoTvc6I+m7wGvpugcionxSva78Lm0zawYq/vLeOAqFQvT29ta7GmZms4qkvogoVDrnJ7PNzCyXE4WZmeVyojAzs1xOFGZmlsuJwszMcjlRmJlZLicKMzPL5URhZma5nCjMzCyXE4WZmeVyojAzs1xOFGZmlsuJwszMcjlRmJlZLicKMzPL5URhZma5nCjMzCyXE4WZmeVyojAzs1xOFGZmlqumRCHpTyQdlPSGpOckfUzSFZL2SHo7fW/PXL9ZUr+ktyStycQ7JR1I5x6RpBS/VNILKb5f0rJa6mtmZhNXdaKQtAj4Y6AQETcArUA3cC+wNyJWAnvTZyRdn86vAtYCj0lqTbd7HNgIrExfa1N8AzAYESuAh4GHqq2vmZlVp9ahpzZgrqQ24DLgXWAdsDWd3wrcmo7XAc9HxEcRcQToB1ZLWgjMi4h9ERHAM2VlSvfaAdxU6m2Ymdn0qDpRRMQvgL8CjgEngA8i4ifA1RFxIl1zArgqFVkEHM/cYiDFFqXj8viIMhExBHwAzC+vi6SNknol9Z46daraJpmZWQW1DD21U/yN/1rgGuDjkr6SV6RCLHLieWVGBiK2REQhIgoLFizIr7iZmU1ILUNPvwsciYhTEXEOeAn4AvBeGk4ifT+Zrh8AFmfKd1AcqhpIx+XxEWXS8NblwJka6mxmZhNUS6I4BnRJuizNG9wEHAJ2AevTNeuBnel4F9CdVjJdS3HS+tU0PPWhpK50nzvLypTudRvwcprHMDOzadJWbcGI2C9pB/A6MAT8DNgCfALYLmkDxWRye7r+oKTtwJvp+k0RcT7d7m7gaWAusDt9ATwJPCupn2JPorva+k61vqOD9Bw+Tdfy+XQubR+7gJnZLKFG+wW9UChEb2/vtP6ZfUcHueOJHs4ODTOnrYVtd3U5WZjZrCKpLyIKlc75yexJ0HP4NGeHhhkOODc0TM/h0/WukpnZpHGimARdy+czp62FVsElbS10Lb9oBa+Z2axV9RyFXdC5tJ1td3V5jsLMGpITxSTpXNruBGFmDclDT2ZmlsuJYgr0HR3k0Vf66Ts6WO+qmJnVzENPk8xLZc2s0bhHMcm8VNbMGo0TxSTzUlkzazQeeppkXiprZo3GiWIKeKmsmTUSDz2ZmVkuJ4op5qWyZjbbeehpCnmprJk1AvcoppCXyppZI3CimEJeKmtmjcBDT1PIS2XNrBE4UUwxL5U1s9nOQ09mZparpkQh6VOSdkj6uaRDkn5T0hWS9kh6O31vz1y/WVK/pLckrcnEOyUdSOcekaQUv1TSCym+X9KyWuprZmYTV2uP4vvA30fEbwCfAQ4B9wJ7I2IlsDd9RtL1QDewClgLPCapNd3ncWAjsDJ9rU3xDcBgRKwAHgYeqrG+ZmY2QVUnCknzgN8BngSIiLMR8UtgHbA1XbYVuDUdrwOej4iPIuII0A+slrQQmBcR+yIigGfKypTutQO4qdTbmI388J2ZzUa1TGYvB04BfyvpM0AfcA9wdUScAIiIE5KuStcvAnoy5QdS7Fw6Lo+XyhxP9xqS9AEwH3g/WxFJGyn2SFiyZEkNTZo65Q/f3XfLKgZ/ddarocxsxqslUbQBnwO+FhH7JX2fNMw0iko9gciJ55UZGYjYAmwBKBQKF52fCbIP3509N8x9O99gOMJJw8xmvFoSxQAwEBH70+cdFBPFe5IWpt7EQuBk5vrFmfIdwLsp3lEhni0zIKkNuBw4U0Od66b08N25oWEkMRxRMWl4mw8zm2mqnqOIiH8Gjku6LoVuAt4EdgHrU2w9sDMd7wK600qmaylOWr+ahqk+lNSV5h/uLCtTutdtwMtpHmPWKT18942br+OBdTf8+ontlpYLScPbfJjZTFTrA3dfA7ZJmgMcBv6IYvLZLmkDcAy4HSAiDkraTjGZDAGbIuJ8us/dwNPAXGB3+oLiRPmzkvop9iS6a6xvXWUfvrvu05+k5/Bp2i+bwwM/Osi5oWEuaWuh/bI5PPpKv4ehzGzG0Cz9BX1UhUIhent7612NCek7OjgiaXi3WTObbpL6IqJQ6Zy38JgBSj2NR1/pr7jbbGmvqOyxE4iZTRcnihkkO+FdGoYqLaltaxFIDJ13b8PMppcTxQxSvtvsiPdZnA8gCC70NpwozGw6OFHMMOW7zZZ6GK2pR3H+/LDfbWFm08qJYgYr72GA5yjMbPo5Ucxw5T0MJwgzm25+H4WZmeVyojAzs1xOFGZmlsuJwszMcjlRmJlZLieKWcpvyzOz6eLlsbNQ+dvyvJ2HmU0l9yhmoRFbe/gdFmY2xZwoZqHS5oGtYsQ7LDwMZWZTwUNPs1B2aw+/w8LMppp7FLNU59J2Nn1xBYO/OuthKDObUk4Us1z5MJR3lTWzyeahp1mufIdZDzuZ2WSruUchqVXSzyT9KH2+QtIeSW+n7+2ZazdL6pf0lqQ1mXinpAPp3COSlOKXSnohxfdLWlZrfRtRaRjKScLMpsJkDD3dAxzKfL4X2BsRK4G96TOSrge6gVXAWuAxSa2pzOPARmBl+lqb4huAwYhYATwMPDQJ9W1o2Qfx/FCemU2GmoaeJHUAfwj8BfCNFF4H3JiOtwL/AHw7xZ+PiI+AI5L6gdWS3gHmRcS+dM9ngFuB3anMn6d77QD+RpIiImqpd6PKPohX/o7t+25ZxeCvznp4yswmrNY5ir8GvgV8MhO7OiJOAETECUlXpfgioCdz3UCKnUvH5fFSmePpXkOSPgDmA+/XWO+GNNo7ts+eG+a+nW8wHOEltGY2YVUPPUm6BTgZEX3jLVIhFjnxvDLlddkoqVdS76lTp8ZZncYzYgVUq7gkHbe0iOGIXy+hffH1AQ9Jmdm41dKj+C3gS5L+APgYME/S3wHvSVqYehMLgZPp+gFgcaZ8B/BuindUiGfLDEhqAy4HzpRXJCK2AFsACoVC0w5LjfaO7dJDeeeGhmltETv6Bn49JOXehZmNpepEERGbgc0Akm4EvhkRX5H0l8B64MH0fWcqsgv4oaTvAddQnLR+NSLOS/pQUhewH7gT+EGmzHpgH3Ab8LLnJ/KN9o7t6z79SXoOn+bdX/4/nnv12IjeRXli8TyGmWVNxXMUDwLbJW0AjgG3A0TEQUnbgTeBIWBTRJxPZe4GngbmUpzE3p3iTwLPponvMxRXTVkVSgmk7+ggL74+cFHvonzy2z0NMytRo/2CXigUore3t97VmNH6jg5e1LsoTQYF0Cr4xs3XsemLK+pZTTObRpL6IqJQ6Zy38GhCpQf0/sPnOipOfntHWjPL8hYeTWysyW/vSGtm4ETR9CpNfj/6Sv9FO9I6UZg1Lw892UW8I62ZZblHYRepNCT16Cv9XjZr1qScKKyi7HLa0v5Rnq8wa04eerJcI/aP8hv0zJqSE4XlKp+v8LJZs+bjoSfLlZ2v8LJZs+bkRGFjKs1XVFo2C3ivKLMG50Rh41Yahjo3NPzrYajRXpTk3oZZ43CisHErXzY72ouSyneldcIwm92cKGxCyp/kLvUwWlOP4vz5i995kX0NK3h4ymy28e6xVpPSTrTZJJDdlbaFC2/Yy3uPd6msE4hZfeTtHutEYZOu9JDeuaFhpAuvYc1uZV5NAskeO5mYTS4nCpt2pZ5G+WtYS8NTE00gecnEScOsdk4UVleVhqcmmkBGSyZeYWU2OfIShSezbcqN9R7v8SSQ0ZKJ3/ttNvXco7AZp1IPZKxk4uEps9p46Mkazljv/fbwlNnETMk7syUtlvSKpEOSDkq6J8WvkLRH0tvpe3umzGZJ/ZLekrQmE++UdCCde0SSUvxSSS+k+H5Jy6qtrzWWsd77XUoS3vXWrHa1zFEMAX8aEa9L+iTQJ2kP8J+AvRHxoKR7gXuBb0u6HugGVgHXAP9T0r+OiPPA48BGoAf4H8BaYDewARiMiBWSuoGHgC/XUGdrMGO997u03Yjf0mdWvaoTRUScAE6k4w8lHQIWAeuAG9NlW4F/AL6d4s9HxEfAEUn9wGpJ7wDzImIfgKRngFspJop1wJ+ne+0A/kaSotHGy6wm45ksL72EKW/uw3MZZpVNyqqnNCT0WWA/cHVKIkTECUlXpcsWUewxlAyk2Ll0XB4vlTme7jUk6QNgPvB+2Z+/kWKPhCVLlkxGk6wBZBNI9k19430+A5xMzGASEoWkTwAvAl+PiH9J0wsVL60Qi5x4XpmRgYgtwBYoTmaPVWdrPqNuYJg5PntumPt2vuGH/czK1JQoJF1CMUlsi4iXUvg9SQtTb2IhcDLFB4DFmeIdwLsp3lEhni0zIKkNuBw4U0udrTllt0gf1/MZ40gm3q/KmkXViSKtTHoSOBQR38uc2gWsBx5M33dm4j+U9D2Kk9krgVcj4rykDyV1URy6uhP4Qdm99gG3AS97fsKqMdqkdy0P+43WA/FyXGs0VT9HIem3gX8EDgDDKfxnFH/YbweWAMeA2yPiTCrzHeCrFFdMfT0idqd4AXgamEtxEvtrERGSPgY8S3H+4wzQHRGH8+rl5yisFhN52G+07UZaBV9evYRFn5rrnobNGn7gzmwSjbXhYd7T4u5p2EzlvZ7MJlF2NVWl/aqyT4vnvfmvdH2l5btOJjaTOFGY1aDSMxx9Rwd58fWB3Df/VVpJ9cCPDnJ2aPzLdEc7dpKxyeahJ7MpMNab/8rnNL6w4kr+V//7uW8FHM9xrUkme+yE01w89GQ2zSbS07ikrYXfv2Ehr71z5qJJ8tGW6dbyLEg1CcdDY83NPQqzaTTaqqrsD+LxLNMdz/Ld0V78NJ7j8t13qxkaczKZXbzqyWyWGc++VJWOa0kyoyWcaobGPM8y+zhRmDWRapNM3u67pR5F3vMjE333uffcmlmcKMxswsrnJCYyNFbLEFitPZbx7hQ80eNGT0xOFGY2qap5Xe1kzrOMlkzK51NqmdBvttVkThRmNu2mcp4lb/uU7HxKLRP6kzWUVunp/In895iuZOTlsWY27UZ7odR4jis98T6eZFK+1LiWCf2J7iw8ruP0dP5Lrw9Mao9nqreKcaIwsxlnPElmtGTSubR9zERTr9Vkl7S1IBjz3Si1JqOew6cnNVF46MnMbBwmc4L8jid6JrXHU56MqulReI7CzGwGmYpVWdnjyZ6jcKIwM7PcRNEy3ZUxM7PZxYnCzMxyOVGYmVkuJwozM8vlRGFmZrmcKMzMLFfDLY+VdAo4WsMtrgTen6TqzBbN2GZoznY3Y5uhOds90TYvjYgFlU40XKKolaTe0dYSN6pmbDM0Z7ubsc3QnO2ezDZ76MnMzHI5UZiZWS4niottqXcF6qAZ2wzN2e5mbDM0Z7snrc2eozAzs1zuUZiZWS4nCjMzy+VEkUhaK+ktSf2S7q13faaKpMWSXpF0SNJBSfek+BWS9kh6O32fmW+Ar4GkVkk/k/Sj9LkZ2vwpSTsk/Tz9P//NRm+3pD9Jf7ffkPScpI81YpslPSXppKQ3MrFR2ylpc/r59pakNRP5s5woKP4AAR4Ffh+4HviPkq6vb62mzBDwpxHxb4AuYFNq673A3ohYCexNnxvNPcChzOdmaPP3gb+PiN8APkOx/Q3bbkmLgD8GChFxA9AKdNOYbX4aWFsWq9jO9G+8G1iVyjyWfu6NixNF0WqgPyIOR8RZ4HlgXZ3rNCUi4kREvJ6OP6T4g2MRxfZuTZdtBW6tSwWniKQO4A+BJzLhRm/zPOB3gCcBIuJsRPySBm830AbMldQGXAa8SwO2OSJ+CpwpC4/WznXA8xHxUUQcAfop/twbFyeKokXA8czngRRraJKWAZ8F9gNXR8QJKCYT4Ko6Vm0q/DXwLWA4E2v0Ni8HTgF/m4bcnpD0cRq43RHxC+CvgGPACeCDiPgJDdzmMqO1s6afcU4URaoQa+h1w5I+AbwIfD0i/qXe9ZlKkm4BTkZEX73rMs3agM8Bj0fEZ4H/S2MMuYwqjcmvA64FrgE+Lukr9a3VjFDTzzgniqIBYHHmcwfF7mpDknQJxSSxLSJeSuH3JC1M5xcCJ+tVvynwW8CXJL1DcVjx30v6Oxq7zVD8ez0QEfvT5x0UE0cjt/t3gSMRcSoizgEvAV+gsducNVo7a/oZ50RR9BqwUtK1kuZQnPTZVec6TQlJojhmfSgivpc5tQtYn47XAzunu25TJSI2R0RHRCyj+P/25Yj4Cg3cZoCI+GfguKTrUugm4E0au93HgC5Jl6W/6zdRnIdr5DZnjdbOXUC3pEslXQusBF4d7039ZHYi6Q8ojmO3Ak9FxF/Ut0ZTQ9JvA/8IHODCeP2fUZyn2A4sofiP7faIKJ8om/Uk3Qh8MyJukTSfBm+zpH9HcQJ/DnAY+COKvyA2bLsl/RfgyxRX+P0MuAv4BA3WZknPATdS3E78PeB+4L8zSjslfQf4KsX/Ll+PiN3j/rOcKMzMLI+HnszMLJcThZmZ5XKiMDOzXE4UZmaWy4nCzMxyOVGYmVkuJwozM8v1/wG9D9OuhJy/0gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.plot(x, y, '.')\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab13949",
   "metadata": {},
   "source": [
    "And unexpectedly, the word frequency distribution also follows Zipf's law as well. What that means is that we can essentially remove uncommon words, without worrying that they will affect performance. We will also need to remove stopwords, and add unigrams and bigrams as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27098b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=500, ngram_range=(1,2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "42935e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(527677, 988)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0de54b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_bow = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "154941b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(clf):\n",
    "    print(\"_\" * 80)\n",
    "    print(\"Training: \")\n",
    "    clf.fit(X_train_bow, y_train)\n",
    "    y_dev_pred = clf.predict(X_dev_bow)\n",
    "    \n",
    "    score = accuracy_score(y_dev, y_dev_pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \n",
    "    print(\"classification report:\")\n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "    \n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(y_dev, y_dev_pred))\n",
    "    print(\"Training Complete\")\n",
    "    print()\n",
    "    \n",
    "    clf_descr = str(clf).split(\"(\")[0]\n",
    "    return clf_descr, score, y_dev_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75686f55",
   "metadata": {},
   "source": [
    "It's training time! We'll start with a few dummy classifiers, followed by Naive Bayes and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4506c1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results - Dummy Classifiers\n",
      "Uniform Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.501\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.50      0.60     48901\n",
      "           1       0.26      0.50      0.34     17059\n",
      "\n",
      "    accuracy                           0.50     65960\n",
      "   macro avg       0.50      0.50      0.47     65960\n",
      "weighted avg       0.62      0.50      0.53     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[24482 24419]\n",
      " [ 8480  8579]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Dummy Classifiers\n",
      "Most Frequent Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.741\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      1.00      0.85     48901\n",
      "           1       0.00      0.00      0.00     17059\n",
      "\n",
      "    accuracy                           0.74     65960\n",
      "   macro avg       0.37      0.50      0.43     65960\n",
      "weighted avg       0.55      0.74      0.63     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[48901     0]\n",
      " [17059     0]]\n",
      "Training Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for clf, name in (\n",
    "    (DummyClassifier(strategy='uniform', random_state=RANDOM_SEED), \"Uniform Classifier\"),\n",
    "    (DummyClassifier(strategy='most_frequent', random_state=RANDOM_SEED), \"Most Frequent Classifier\"),\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results - Dummy Classifiers\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6228c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "MultinomialNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.882\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     48901\n",
      "           1       0.77      0.77      0.77     17059\n",
      "\n",
      "    accuracy                           0.88     65960\n",
      "   macro avg       0.85      0.85      0.85     65960\n",
      "weighted avg       0.88      0.88      0.88     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[44988  3913]\n",
      " [ 3902 13157]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "BernoulliNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.848\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90     48901\n",
      "           1       0.74      0.63      0.68     17059\n",
      "\n",
      "    accuracy                           0.85     65960\n",
      "   macro avg       0.81      0.78      0.79     65960\n",
      "weighted avg       0.84      0.85      0.84     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[45155  3746]\n",
      " [ 6309 10750]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "ComplementNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.860\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.86      0.90     48901\n",
      "           1       0.68      0.86      0.76     17059\n",
      "\n",
      "    accuracy                           0.86     65960\n",
      "   macro avg       0.81      0.86      0.83     65960\n",
      "weighted avg       0.88      0.86      0.86     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[42001  6900]\n",
      " [ 2353 14706]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.874\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.88      0.91     48901\n",
      "           1       0.71      0.86      0.78     17059\n",
      "\n",
      "    accuracy                           0.87     65960\n",
      "   macro avg       0.83      0.87      0.85     65960\n",
      "weighted avg       0.89      0.87      0.88     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[43014  5887]\n",
      " [ 2439 14620]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "\n",
    "for clf, name in (\n",
    "    (MultinomialNB(alpha=0.01), \"MultinomialNB\"),\n",
    "    (BernoulliNB(alpha=0.01), \"BernoulliNB\"),\n",
    "    (ComplementNB(alpha=0.1), \"ComplementNB\"),\n",
    "    (LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED), \"Logistic Regression\")\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results - Naive Bayes & LogReg\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)\n",
    "    preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7bd9b5",
   "metadata": {},
   "source": [
    "The baseline results are quite promising, with both MultinomialNB and Logistic Regression achieving 0.85 on macro F1-score. This means that the bag-of-word approach is a rather solid approach for sentiment classification. It's also interesting to see that while MultinomialNB has a rather balanced number of false pos and false neg, BernoulliNB and ComplementNB are different. BernoulliNB has a much higher number of fps, while ComplementNB has a much higher number of fns.\n",
    "\n",
    "Also, according to https://web.stanford.edu/~jurafsky/slp3/4.pdf, using binary NB (BernoulliNB) may improve predictive performance, as whether a word occurs or not seems to matter more than its frequency. But in this case, BernoulliNB does not outperform other Naive Bayes methods. We'll come back to this in a second.\n",
    "\n",
    "Let's take a look at a few of mis-classifications for both Naive Bayes and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e6fae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for mis-classifications\n",
    "def create_mis_classification_df(name):\n",
    "    mis_class = pd.DataFrame(X_dev)\n",
    "    mis_class['Actual'] = y_dev\n",
    "    mis_class['Predicted'] = preds[name]\n",
    "    mis_class = mis_class[mis_class['Actual'] != mis_class['Predicted']]\n",
    "    return mis_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48696732",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_class_multi = create_mis_classification_df('MultinomialNB')\n",
    "mis_class_bernoulli = create_mis_classification_df('BernoulliNB')\n",
    "mis_class_complement = create_mis_classification_df('ComplementNB')\n",
    "mis_class_logreg = create_mis_classification_df('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "83f232f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['I liked this app because Mcent is giving 40 rs', 0, 1],\n",
       "       ['等了一個小時 白等了 等了那麼久才取消', 1, 0],\n",
       "       ['There must be a feature to keep check and balance on food quality, Most of time I received substandard food from different restaurants, not even brands like KFC or Subway is doing good on Foodpanda',\n",
       "        0, 1],\n",
       "       [\"I'll give 5 for fast delivery and the rider always calls you when they arrive unlike others they won't even bother calling. Sometimes text won't work on me since I'm not receiving it or sometimes delayed text messages.\",\n",
       "        0, 1],\n",
       "       ['Kalau pagi lambat sama mahal', 0, 1],\n",
       "       ['there is no much offers.. and delivery chrge is high even for restaurants 500m away',\n",
       "        1, 0],\n",
       "       ['ডার্চবাংলা ব্যাংকের ডেবিট কার্ড থেকে বিল দেয়া সিস্টেম থাকলে ভালো হতো।',\n",
       "        1, 0],\n",
       "       ['Cannot edit my home address. 😑', 1, 0],\n",
       "       ['Food is often cold so I am hesitant to use deliveroo over uber eats',\n",
       "        0, 1],\n",
       "       ['Email addresses', 0, 1]], dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_multi.sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2b1f630c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Good but not better', 1, 0],\n",
       "       ['faltu', 1, 0],\n",
       "       ['Overpriced', 1, 0],\n",
       "       ['It would helpful if there is a pop out that first confirm the orders before proceeding. Sometimes, I would accidentally click the confirm button and it really is troublesome to cancel the order because accidentally clicking confirm button. Overall, the app is smooth and have a good interface.',\n",
       "        0, 1],\n",
       "       ['Everything is good but why cant you top up your grab wallet at conveniences store????',\n",
       "        1, 0],\n",
       "       ['unrespect people who are working', 1, 0],\n",
       "       ['The I Love Milktea From Talamban Times Square isnt Working it Says Unavailable for Delivery My Location Is in 267 Jakosalem St.',\n",
       "        0, 1],\n",
       "       [\"I did have issues with my payment method which now works, no idea why BUT... other than that, it is a perfect app for a takeaway. The other one doesn't have some of the popular takeaways in it, this one does!\",\n",
       "        0, 1],\n",
       "       ['Needs better customer support', 0, 1],\n",
       "       ['Bắt up cả cmt thông tin người dùng lên cái ví cùi mà ko có điều khoản nào nhắc đến việc đền bù nếu để lộ thông tin cá nhân người dùng cả. Ai đảm bảo việc lưu thông tin người dùng trên Ví cùi này là ko bị lộ? xoá app..byebye',\n",
       "        1, 0]], dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_bernoulli.sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0bb7438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"Pop up notification a day right smack in the middle of the screen. It's annoying especially when you are in the middle of something like a video call or writing an email. Kills the customer experience. Would be better if you move such ads/alerts to the notification bar and follow best practices. Uninstalling till then.\",\n",
       "        0, 1],\n",
       "       ['So far only 1 bad experience.', 0, 1],\n",
       "       ['I enjoyed using the app, however the location system is a bit floored. I cant order food from places that are 10 minutes away, but i can order from places that are over 30. I believe this to be because it goes on my post code rather than distance, its quite annoying and I would rate higher if the issue was fixed.',\n",
       "        0, 1],\n",
       "       ['Ok laa', 1, 0],\n",
       "       ['Mast app hai yaar kuch bhi order karo or kahi se bhi nic', 0, 1],\n",
       "       ['Would be better if we can send a message to the stores din 😆',\n",
       "        0, 1],\n",
       "       [\"Please put option to put reviews right away. I've been ordering lately and the app hasn't shown me the option to rate my recent order. Please fix it\",\n",
       "        0, 1],\n",
       "       ['Hope it has a gcash payment.', 0, 1],\n",
       "       [\"I like this app very much , very good. Cash on delivery is good becuz not everyone hold Credit card App is good, no issues if someone facing issues they need to leave the app, don't use it if you dont like it.\",\n",
       "        0, 1],\n",
       "       ['Been ordering for a while now and the app has never let me down.',\n",
       "        0, 1]], dtype=object)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_complement.sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "18c31000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Good', 1, 0],\n",
       "       ['Had a couple of glitches and got double charged but other than that fine',\n",
       "        0, 1],\n",
       "       ['Some resturents are spoiled the image of foodpanda. so Foodpanda should banned them otherwise people are betrayed by them..',\n",
       "        0, 1],\n",
       "       ['Rất chậm, kém trong xử lý vấn đề thẻ thanh toán của tôi bị lỗi',\n",
       "        1, 0],\n",
       "       ['Penghantarannya bagusss tapi sayang guna motor personal..semua sektor/service Penghantaran sepatutnya menyediakan kenderaan company..',\n",
       "        0, 1],\n",
       "       ['boring', 1, 0],\n",
       "       ['No good', 1, 0],\n",
       "       ['Food prices keep increase.', 0, 1],\n",
       "       ['I have a question why the payment method via CREDIT/DEBIT CARD is not working?',\n",
       "        0, 1],\n",
       "       ['the ridera are very slpw 2 times the food arrived cold', 0, 1]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_logreg.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa3993d",
   "metadata": {},
   "source": [
    "Really interesting. Looking at the results, there are a few cases of mis-classifications:\n",
    "- Reviews that are not in English. Presumably reviews not in English won't be as robust in terms of tokenization and vectorization. (Note: even with filter, there is no obvious improvement. The language detector also returns some very weird mistakes.)\n",
    "- Reviews that contain negation expressions, eg \"no good\" is classified as a positive review when in reality it should be negative. BoW approach makes it hard for ML model to recognize this kind of expressions.\n",
    "- Reviews that are mis-classified due to rating. Eg a customer may write something negative but give 3 stars. It's tricky in this case because it's a caveat of our dataset.\n",
    "- Some mis-classification is the ML model being weirdly off, eg ComplementNB classified a \"Good\" review as negative, or reviews containing the word 'hate' gets classified as positive.\n",
    "- Contextual awareness is important and this is something that bag-of-word approaches cannot address. For example the sentence 'Very good. Expensive delivery charge though' gets classified as negative likely because of the word expensive, while in reality this is a positive review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b02b0da",
   "metadata": {},
   "source": [
    "### 2.1 Reduce min_df\n",
    "\n",
    "We set a min frequency cap of 500. What happens if we reduce this cap to 100?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3069fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=100, ngram_range=(1,2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_dev_bow = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04437490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "MultinomialNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.894\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.92      0.93     48901\n",
      "           1       0.78      0.82      0.80     17059\n",
      "\n",
      "    accuracy                           0.89     65960\n",
      "   macro avg       0.86      0.87      0.86     65960\n",
      "weighted avg       0.90      0.89      0.89     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[44892  4009]\n",
      " [ 2986 14073]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "BernoulliNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.853\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.92      0.90     48901\n",
      "           1       0.75      0.65      0.69     17059\n",
      "\n",
      "    accuracy                           0.85     65960\n",
      "   macro avg       0.82      0.79      0.80     65960\n",
      "weighted avg       0.85      0.85      0.85     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[45174  3727]\n",
      " [ 5993 11066]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "ComplementNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.871\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.91     48901\n",
      "           1       0.69      0.90      0.78     17059\n",
      "\n",
      "    accuracy                           0.87     65960\n",
      "   macro avg       0.83      0.88      0.85     65960\n",
      "weighted avg       0.89      0.87      0.88     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[42111  6790]\n",
      " [ 1734 15325]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.889\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92     48901\n",
      "           1       0.74      0.89      0.81     17059\n",
      "\n",
      "    accuracy                           0.89     65960\n",
      "   macro avg       0.85      0.89      0.86     65960\n",
      "weighted avg       0.90      0.89      0.89     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[43498  5403]\n",
      " [ 1919 15140]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "\n",
    "for clf, name in (\n",
    "    (MultinomialNB(alpha=0.01), \"MultinomialNB\"),\n",
    "    (BernoulliNB(alpha=0.01), \"BernoulliNB\"),\n",
    "    (ComplementNB(alpha=0.1), \"ComplementNB\"),\n",
    "    (LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED), \"Logistic Regression\")\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results - Naive Bayes & LogReg\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)\n",
    "    preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43752fc7",
   "metadata": {},
   "source": [
    "Slight bump in performance, but at the expense of longer training time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab34f0",
   "metadata": {},
   "source": [
    "### 2.2 Not use stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "50f0ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=100, ngram_range=(1,2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_dev_bow = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d6e95fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "MultinomialNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.896\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.91      0.93     48901\n",
      "           1       0.77      0.85      0.81     17059\n",
      "\n",
      "    accuracy                           0.90     65960\n",
      "   macro avg       0.86      0.88      0.87     65960\n",
      "weighted avg       0.90      0.90      0.90     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[44686  4215]\n",
      " [ 2632 14427]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "BernoulliNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.825\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.91      0.88     48901\n",
      "           1       0.69      0.59      0.63     17059\n",
      "\n",
      "    accuracy                           0.82     65960\n",
      "   macro avg       0.78      0.75      0.76     65960\n",
      "weighted avg       0.82      0.82      0.82     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[44421  4480]\n",
      " [ 7069  9990]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "ComplementNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.876\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91     48901\n",
      "           1       0.70      0.91      0.79     17059\n",
      "\n",
      "    accuracy                           0.88     65960\n",
      "   macro avg       0.83      0.89      0.85     65960\n",
      "weighted avg       0.90      0.88      0.88     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[42187  6714]\n",
      " [ 1479 15580]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.904\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.90      0.93     48901\n",
      "           1       0.77      0.90      0.83     17059\n",
      "\n",
      "    accuracy                           0.90     65960\n",
      "   macro avg       0.87      0.90      0.88     65960\n",
      "weighted avg       0.91      0.90      0.91     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[44242  4659]\n",
      " [ 1704 15355]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "\n",
    "for clf, name in (\n",
    "    (MultinomialNB(alpha=0.01), \"MultinomialNB\"),\n",
    "    (BernoulliNB(alpha=0.01), \"BernoulliNB\"),\n",
    "    (ComplementNB(alpha=0.1), \"ComplementNB\"),\n",
    "    (LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED), \"Logistic Regression\")\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results - Naive Bayes & LogReg\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)\n",
    "    preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2a19e6",
   "metadata": {},
   "source": [
    "Performance improved, surprisingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94477f7",
   "metadata": {},
   "source": [
    "### 2.3 Set max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c9b9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=100, max_df=5000, ngram_range=(1,2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_dev_bow = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "332660b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "MultinomialNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.895\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.95      0.93     48901\n",
      "           1       0.83      0.75      0.79     17059\n",
      "\n",
      "    accuracy                           0.89     65960\n",
      "   macro avg       0.87      0.85      0.86     65960\n",
      "weighted avg       0.89      0.89      0.89     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[46212  2689]\n",
      " [ 4250 12809]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "BernoulliNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.836\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.92      0.89     48901\n",
      "           1       0.72      0.59      0.65     17059\n",
      "\n",
      "    accuracy                           0.84     65960\n",
      "   macro avg       0.80      0.76      0.77     65960\n",
      "weighted avg       0.83      0.84      0.83     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[45056  3845]\n",
      " [ 6954 10105]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "ComplementNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.886\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92     48901\n",
      "           1       0.74      0.87      0.80     17059\n",
      "\n",
      "    accuracy                           0.89     65960\n",
      "   macro avg       0.84      0.88      0.86     65960\n",
      "weighted avg       0.90      0.89      0.89     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[43559  5342]\n",
      " [ 2183 14876]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.899\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93     48901\n",
      "           1       0.77      0.86      0.82     17059\n",
      "\n",
      "    accuracy                           0.90     65960\n",
      "   macro avg       0.86      0.89      0.87     65960\n",
      "weighted avg       0.90      0.90      0.90     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[44565  4336]\n",
      " [ 2321 14738]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "\n",
    "for clf, name in (\n",
    "    (MultinomialNB(alpha=0.01), \"MultinomialNB\"),\n",
    "    (BernoulliNB(alpha=0.01), \"BernoulliNB\"),\n",
    "    (ComplementNB(alpha=0.1), \"ComplementNB\"),\n",
    "    (LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED), \"Logistic Regression\")\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results - Naive Bayes & LogReg\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)\n",
    "    preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689aa697",
   "metadata": {},
   "source": [
    "Not much changes from stopwords removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503bb7c",
   "metadata": {},
   "source": [
    "### 2.4 Clip frequency at 1\n",
    "\n",
    "Earlier, we see that there isn't any performance with BernoulliNB as compared to other methods. But what if we clip the frequency at the feature processing level? Luckily, sklearn tfidf has a `binary` parameters that allows us to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9936465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(binary=True, ngram_range=(1,1))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_dev_bow = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e08ddff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "MultinomialNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.887\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.91      0.92     48901\n",
      "           1       0.76      0.81      0.79     17059\n",
      "\n",
      "    accuracy                           0.89     65960\n",
      "   macro avg       0.85      0.86      0.86     65960\n",
      "weighted avg       0.89      0.89      0.89     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[44624  4277]\n",
      " [ 3197 13862]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "BernoulliNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.828\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.90      0.89     48901\n",
      "           1       0.69      0.62      0.65     17059\n",
      "\n",
      "    accuracy                           0.83     65960\n",
      "   macro avg       0.78      0.76      0.77     65960\n",
      "weighted avg       0.82      0.83      0.83     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[44098  4803]\n",
      " [ 6530 10529]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "ComplementNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.868\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.90     48901\n",
      "           1       0.68      0.92      0.78     17059\n",
      "\n",
      "    accuracy                           0.87     65960\n",
      "   macro avg       0.82      0.88      0.84     65960\n",
      "weighted avg       0.89      0.87      0.87     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[41580  7321]\n",
      " [ 1418 15641]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.903\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93     48901\n",
      "           1       0.76      0.91      0.83     17059\n",
      "\n",
      "    accuracy                           0.90     65960\n",
      "   macro avg       0.86      0.90      0.88     65960\n",
      "weighted avg       0.91      0.90      0.91     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[44077  4824]\n",
      " [ 1581 15478]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "\n",
    "for clf, name in (\n",
    "    (MultinomialNB(alpha=0.01), \"MultinomialNB\"),\n",
    "    (BernoulliNB(alpha=0.01), \"BernoulliNB\"),\n",
    "    (ComplementNB(alpha=0.1), \"ComplementNB\"),\n",
    "    (LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED), \"Logistic Regression\")\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results - Naive Bayes & LogReg\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)\n",
    "    preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d9835",
   "metadata": {},
   "source": [
    "### 2.5 Tune Logistic Regression Params\n",
    "\n",
    "So far, LogReg performs the best in terms of macro F1 score. In this section, we'll try tuning the performance of Logistic Regression, using the best Tfidf tuning result above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ec767c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=100, ngram_range=(1,2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_dev_bow = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3bbdc5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LogReg Grid Search\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{'C': 4.281332398719396}\n",
      "accuracy:   0.904\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93     48901\n",
      "           1       0.77      0.90      0.83     17059\n",
      "\n",
      "    accuracy                           0.90     65960\n",
      "   macro avg       0.87      0.90      0.88     65960\n",
      "weighted avg       0.91      0.90      0.91     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[44336  4565]\n",
      " [ 1779 15280]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=3000, random_state=RANDOM_SEED)\n",
    "param_grid = {'C' : np.logspace(-4, 4, 20)}\n",
    "\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LogReg Grid Search\")\n",
    "clf = GridSearchCV(clf, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(X_train_bow, y_train)\n",
    "print(clf.best_params_)\n",
    "y_dev_pred = clf.predict(X_dev_bow)\n",
    "score = accuracy_score(y_dev, y_dev_pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_dev, y_dev_pred))\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_dev, y_dev_pred))\n",
    "print(\"Training Complete\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6398cb94",
   "metadata": {},
   "source": [
    "## 3. Evaluate On Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "88f02387",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_bow = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a00437c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.905\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93     48937\n",
      "           1       0.77      0.90      0.83     17023\n",
      "\n",
      "    accuracy                           0.90     65960\n",
      "   macro avg       0.87      0.90      0.88     65960\n",
      "weighted avg       0.91      0.90      0.91     65960\n",
      "\n",
      "confusion matrix:\n",
      "[[44309  4628]\n",
      " [ 1645 15378]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_clf.predict(X_test_bow)\n",
    "score = accuracy_score(y_test, y_test_pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Training Complete\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a60713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
