{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21330d8",
   "metadata": {},
   "source": [
    "## Sentiment Classification SG Reviews Data (BOW, non-Deep Learning)\n",
    "\n",
    "This notebook covers two good approaches to perform sentiment classification - Naive Bayes and Logistic Regression. We will train SG reviews data on both.\n",
    "\n",
    "As a rule of thumb, reviews that are 3 stars and above are **positive**, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edd1171c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy in /home/meln/.local/lib/python3.8/site-packages (3.2.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy) (2.25.1)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (0.6.1)\n",
      "Requirement already satisfied: jinja2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (3.0.8)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (1.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (8.0.13)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy) (1.20.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (2.4.2)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (2.0.6)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (1.8.2)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (1.0.1)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (3.0.6)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (0.7.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy) (4.59.0)\n",
      "Requirement already satisfied: setuptools in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy) (52.0.0.post20210125)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy) (20.9)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy) (0.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from packaging>=20.0->spacy) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/meln/.local/lib/python3.8/site-packages (from pathy>=0.3.5->spacy) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from jinja2->spacy) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a09b873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /home/meln/.local/lib/python3.8/site-packages (4.1.2)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/meln/.local/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from gensim) (1.20.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b213884b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: spacy_langdetect in /home/meln/.local/lib/python3.8/site-packages (0.1.2)\n",
      "Requirement already satisfied: pytest in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy_langdetect) (6.2.3)\n",
      "Requirement already satisfied: langdetect==1.0.7 in /home/meln/.local/lib/python3.8/site-packages (from spacy_langdetect) (1.0.7)\n",
      "Requirement already satisfied: six in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from langdetect==1.0.7->spacy_langdetect) (1.15.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pytest->spacy_langdetect) (20.3.0)\n",
      "Requirement already satisfied: iniconfig in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pytest->spacy_langdetect) (1.1.1)\n",
      "Requirement already satisfied: packaging in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pytest->spacy_langdetect) (20.9)\n",
      "Requirement already satisfied: pluggy<1.0.0a1,>=0.12 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pytest->spacy_langdetect) (0.13.1)\n",
      "Requirement already satisfied: py>=1.8.2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pytest->spacy_langdetect) (1.10.0)\n",
      "Requirement already satisfied: toml in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pytest->spacy_langdetect) (0.10.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from packaging->pytest->spacy_langdetect) (2.4.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install spacy_langdetect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad89d88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting en-core-web-sm==3.2.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 13.9 MB 23.0 MB/s eta 0:00:01    |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ                          | 2.6 MB 23.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /home/meln/.local/lib/python3.8/site-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
      "Requirement already satisfied: pathy>=0.3.5 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.25.1)\n",
      "Requirement already satisfied: setuptools in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: numpy>=1.15.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.20.1)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (20.9)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.59.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/meln/.local/lib/python3.8/site-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.7)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /home/meln/.local/lib/python3.8/site-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.7.4.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2020.12.5)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.0.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.1.1)\n",
      "\u001b[38;5;2mâœ” Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "926204c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import spacy\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from spacy.language import Language\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22215586",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1fcb6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>Used to be a good app been using for years, no...</td>\n",
       "      <td>5</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>Grab app is convenient because you can use mul...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>I used to love the subscription plans that the...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-06</td>\n",
       "      <td>I ordered a grabfood and one of the 3 items ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-26</td>\n",
       "      <td>This platform gives too much power to restaura...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             review  rating  \\\n",
       "0  2020-09-30  Used to be a good app been using for years, no...       5   \n",
       "1  2020-08-21  Grab app is convenient because you can use mul...       1   \n",
       "2  2020-11-18  I used to love the subscription plans that the...       1   \n",
       "3  2021-11-06  I ordered a grabfood and one of the 3 items ar...       1   \n",
       "4  2021-09-26  This platform gives too much power to restaura...       1   \n",
       "\n",
       "        app  \n",
       "0  GrabFood  \n",
       "1  GrabFood  \n",
       "2  GrabFood  \n",
       "3  GrabFood  \n",
       "4  GrabFood  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sg = pd.read_pickle(\"assets/sg_reviews.pkl\")\n",
    "reviews_sg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49be95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_sg['label'] = np.where(reviews_sg['rating'] >= 3, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "570595bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>app</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>Used to be a good app been using for years, no...</td>\n",
       "      <td>5</td>\n",
       "      <td>GrabFood</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>Grab app is convenient because you can use mul...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>I used to love the subscription plans that the...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-06</td>\n",
       "      <td>I ordered a grabfood and one of the 3 items ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-26</td>\n",
       "      <td>This platform gives too much power to restaura...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             review  rating  \\\n",
       "0  2020-09-30  Used to be a good app been using for years, no...       5   \n",
       "1  2020-08-21  Grab app is convenient because you can use mul...       1   \n",
       "2  2020-11-18  I used to love the subscription plans that the...       1   \n",
       "3  2021-11-06  I ordered a grabfood and one of the 3 items ar...       1   \n",
       "4  2021-09-26  This platform gives too much power to restaura...       1   \n",
       "\n",
       "        app  label  \n",
       "0  GrabFood      0  \n",
       "1  GrabFood      1  \n",
       "2  GrabFood      1  \n",
       "3  GrabFood      1  \n",
       "4  GrabFood      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae770f7",
   "metadata": {},
   "source": [
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f956a36",
   "metadata": {},
   "source": [
    "Check the dataset size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f9a3f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "659684\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_sg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e629cae",
   "metadata": {},
   "source": [
    "And the type of apps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64d82e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GrabFood', 'Deliveroo', 'FoodPanda']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_list = list(reviews_sg['app'].unique())\n",
    "app_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1180a133",
   "metadata": {},
   "source": [
    "Let's also get a sense of our dataset's balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5fd33ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.740038\n",
       "1    0.259962\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sg['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1feda2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.749\n",
      "1    0.251\n",
      "Name: label, dtype: float64\n",
      "0    0.658943\n",
      "1    0.341057\n",
      "Name: label, dtype: float64\n",
      "0    0.747103\n",
      "1    0.252897\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# By app\n",
    "\n",
    "for app in app_list:\n",
    "    print(reviews_sg[reviews_sg['app'] == app]['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a556a3",
   "metadata": {},
   "source": [
    "Across the board the distribution of positive and negative reviews are quite consistent between the apps. Overall, there's an imbalance in our dataset, with positive reviews making for 75% of the dataset. Let's also check for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd9c2c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       0\n",
       "review    87\n",
       "rating     0\n",
       "app        0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_sg.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb8b89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_sg = reviews_sg.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2701e569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Used to be a good app been using for years, no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grab app is convenient because you can use mul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I used to love the subscription plans that the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I ordered a grabfood and one of the 3 items ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This platform gives too much power to restaura...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  Used to be a good app been using for years, no...      0\n",
       "1  Grab app is convenient because you can use mul...      1\n",
       "2  I used to love the subscription plans that the...      1\n",
       "3  I ordered a grabfood and one of the 3 items ar...      1\n",
       "4  This platform gives too much power to restaura...      1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc = reviews_sg.copy()\n",
    "df_proc.drop(columns=['date', 'rating', 'app'], inplace=True)\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cabad71",
   "metadata": {},
   "source": [
    "#### Filter Out Non-English Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3184f6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function __main__.get_lang_detector(nlp, name)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# language detection function\n",
    "def get_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "# Only run this once, or you need to restart the kernel to avoid errors\n",
    "Language.factory(\"language_detector\", func=get_lang_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e344891f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner', 'language_detector']\n"
     ]
    }
   ],
   "source": [
    "#init the nlp function and add language detector to the pipeline\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp.add_pipe('language_detector', last=True)\n",
    "\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "def lan_detect(x):\n",
    "    text=str(x)\n",
    "    with nlp.select_pipes(enable=['parser', 'language_detector']):    \n",
    "        doc = nlp(text)\n",
    "        lan_score=doc._.language\n",
    "    return lan_score['language'], lan_score['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9d706f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = df_proc.sample(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be36c279",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial['language'], trial['cof_score'] = zip(*trial['review'].map(lan_detect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "864a01eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial=trial[trial['language']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6fbff3c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>cof_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8262</th>\n",
       "      <td>Much expensive..ðŸ˜”ðŸ˜”</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>0.857139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478143</th>\n",
       "      <td>Good in service</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294546</th>\n",
       "      <td>Trusted place to get your hungry tummy fed.</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112892</th>\n",
       "      <td>Always frozen screen and does not update locat...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202550</th>\n",
       "      <td>This app are suck ! Can you please do not dedu...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review  label language  \\\n",
       "8262                                   Much expensive..ðŸ˜”ðŸ˜”      0       en   \n",
       "478143                                    Good in service      0       en   \n",
       "294546        Trusted place to get your hungry tummy fed.      0       en   \n",
       "112892  Always frozen screen and does not update locat...      1       en   \n",
       "202550  This app are suck ! Can you please do not dedu...      1       en   \n",
       "\n",
       "        cof_score  \n",
       "8262     0.857139  \n",
       "478143   0.999994  \n",
       "294546   0.999995  \n",
       "112892   0.999998  \n",
       "202550   0.999997  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bd75272f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2812"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trial)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0afa2e",
   "metadata": {},
   "source": [
    "Promising! Now let's do the real thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6e05e458",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc['language'], df_proc['cof_score'] = zip(*df_proc['review'].map(lan_detect))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f3b5eff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc=df_proc[df_proc['language']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4873f469",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>cof_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Used to be a good app been using for years, no...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grab app is convenient because you can use mul...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I used to love the subscription plans that the...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I ordered a grabfood and one of the 3 items ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This platform gives too much power to restaura...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label language  \\\n",
       "0  Used to be a good app been using for years, no...      0       en   \n",
       "1  Grab app is convenient because you can use mul...      1       en   \n",
       "2  I used to love the subscription plans that the...      1       en   \n",
       "3  I ordered a grabfood and one of the 3 items ar...      1       en   \n",
       "4  This platform gives too much power to restaura...      1       en   \n",
       "\n",
       "   cof_score  \n",
       "0   0.999996  \n",
       "1   0.999999  \n",
       "2   0.999999  \n",
       "3   0.999998  \n",
       "4   0.999998  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0120b74c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374633"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_proc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df12e5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_proc.to_csv('reviews_sg_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea35db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_proc['review']\n",
    "y = df_proc['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e23ba",
   "metadata": {},
   "source": [
    "We will split the dataset into `train`, `test`, and `dev`, with 80%, 10%, 10% ratio, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "001cc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_test, X_dev, y_test, y_dev = train_test_split(X_test, y_test, test_size=0.5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "676ca2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299706"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b338cf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37464"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e946dbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37463"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "acc8ec94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Great'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0c23ad78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Food pandas have made it very easy to order food and drink.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70a46a",
   "metadata": {},
   "source": [
    "## 2.1 Bag-of-Words Approach on Naive Bayes & Logistic Regression\n",
    "\n",
    "This section explores the use of bag of words as feature extraction. But first, let's have a look at the token frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2550abec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 299706/299706 [00:11<00:00, 25863.14it/s]\n"
     ]
    }
   ],
   "source": [
    "# Fill this with any token (with anything in it!) for tokens separated by whitespace\n",
    "ws_tokens = Counter()\n",
    "\n",
    "# Fill this one with tokens separated by whitespace but constisting only of tokens\n",
    "# that are totally made of alphanumeric characters (you can use the \\w character\n",
    "# class in making the regex)\n",
    "\n",
    "alpha_ws_tokens = Counter()\n",
    "\n",
    "# Fill this one with the tokens separated by *word boundaries* (not white space) that consist\n",
    "# of alphanumeric characters (use \\w again)\n",
    "alpha_re_tokens = Counter()\n",
    "for review in tqdm(X_train):\n",
    "    ws_review = review.split()\n",
    "    ws_tokens.update(ws_review)\n",
    "    # Note: use fullmatch() as it anchor both the start and end of str. match() won't work.\n",
    "    alpha_ws_tokens.update([re.fullmatch(r'\\w+', word).group() for word in ws_review if re.fullmatch(r'\\w+', word) != None])\n",
    "    alpha_re_tokens.update(re.findall(r'\\w+', review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5196b087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "165065\n",
      "63237\n",
      "72797\n"
     ]
    }
   ],
   "source": [
    "print(len(ws_tokens))\n",
    "print(len(alpha_ws_tokens))\n",
    "print(len(alpha_re_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84d1db31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 147097),\n",
       " ('to', 138446),\n",
       " ('and', 112056),\n",
       " ('I', 95958),\n",
       " ('app', 88816),\n",
       " ('is', 74236),\n",
       " ('it', 65774),\n",
       " ('a', 57737),\n",
       " ('for', 56861),\n",
       " ('order', 54509),\n",
       " ('my', 53233),\n",
       " ('food', 52984),\n",
       " ('of', 44504),\n",
       " ('service', 42460),\n",
       " ('t', 39624),\n",
       " ('in', 38991),\n",
       " ('not', 38673),\n",
       " ('this', 36329),\n",
       " ('but', 36206),\n",
       " ('you', 34278),\n",
       " ('delivery', 34102),\n",
       " ('good', 32641),\n",
       " ('time', 30633),\n",
       " ('i', 28474),\n",
       " ('that', 28243),\n",
       " ('on', 28180),\n",
       " ('use', 26955),\n",
       " ('have', 26541),\n",
       " ('they', 26033),\n",
       " ('with', 25431),\n",
       " ('s', 24581),\n",
       " ('was', 24279),\n",
       " ('Good', 24096),\n",
       " ('me', 23924),\n",
       " ('can', 22668),\n",
       " ('are', 22482),\n",
       " ('very', 21818),\n",
       " ('so', 19700),\n",
       " ('from', 19434),\n",
       " ('be', 18994),\n",
       " ('Very', 18728),\n",
       " ('your', 18631),\n",
       " ('It', 18558),\n",
       " ('no', 18460),\n",
       " ('The', 18020),\n",
       " ('when', 17697),\n",
       " ('Great', 16656),\n",
       " ('at', 15113),\n",
       " ('customer', 14904),\n",
       " ('more', 14162),\n",
       " ('or', 13663),\n",
       " ('up', 13403),\n",
       " ('as', 13401),\n",
       " ('just', 13397),\n",
       " ('get', 13369),\n",
       " ('easy', 13111),\n",
       " ('all', 12933),\n",
       " ('even', 12884),\n",
       " ('will', 12698),\n",
       " ('if', 12623),\n",
       " ('an', 12618),\n",
       " ('restaurant', 12029),\n",
       " ('after', 11340),\n",
       " ('apps', 11321),\n",
       " ('like', 11204),\n",
       " ('there', 11066),\n",
       " ('always', 9954),\n",
       " ('experience', 9947),\n",
       " ('This', 9776),\n",
       " ('restaurants', 9451),\n",
       " ('great', 9356),\n",
       " ('bad', 9324),\n",
       " ('than', 9292),\n",
       " ('now', 9191),\n",
       " ('grab', 9151),\n",
       " ('panda', 9117),\n",
       " ('don', 9096),\n",
       " ('only', 9084),\n",
       " ('payment', 8744),\n",
       " ('one', 8733),\n",
       " ('driver', 8682),\n",
       " ('Easy', 8490),\n",
       " ('has', 8451),\n",
       " ('foodpanda', 8449),\n",
       " ('their', 8418),\n",
       " ('we', 8194),\n",
       " ('been', 8150),\n",
       " ('any', 8120),\n",
       " ('still', 7997),\n",
       " ('by', 7926),\n",
       " ('then', 7895),\n",
       " ('times', 7820),\n",
       " ('had', 7716),\n",
       " ('using', 7648),\n",
       " ('its', 7626),\n",
       " ('really', 7530),\n",
       " ('2', 7515),\n",
       " ('do', 7511),\n",
       " ('because', 7488),\n",
       " ('location', 7431)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_100 = alpha_re_tokens.most_common(100)\n",
    "top_100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc95113",
   "metadata": {},
   "source": [
    "Lots of stopwords, as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e6f87cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = list(range(100))\n",
    "y = [word_tup[1] for word_tup in top_100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "488d0ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.plot(x, y, '.')\n",
    "#plt.yscale('log')\n",
    "#plt.xscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab13949",
   "metadata": {},
   "source": [
    "And unexpectedly, the word frequency distribution also follows Zipf's law as well. What that means is that we can essentially remove uncommon words, without worrying that they will affect performance. We will also need to remove stopwords, and add unigrams and bigrams as features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "27098b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=500, ngram_range=(1,2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "42935e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299706, 834)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_bow.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0de54b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_bow = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "154941b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(clf):\n",
    "    print(\"_\" * 80)\n",
    "    print(\"Training: \")\n",
    "    clf.fit(X_train_bow, y_train)\n",
    "    y_dev_pred = clf.predict(X_dev_bow)\n",
    "    \n",
    "    score = accuracy_score(y_dev, y_dev_pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \n",
    "    print(\"classification report:\")\n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "    \n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(y_dev, y_dev_pred))\n",
    "    print(\"Training Complete\")\n",
    "    print()\n",
    "    \n",
    "    clf_descr = str(clf).split(\"(\")[0]\n",
    "    return clf_descr, score, y_dev_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75686f55",
   "metadata": {},
   "source": [
    "It's training time! We'll start with a few dummy classifiers, followed by Naive Bayes and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4506c1ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results - Dummy Classifiers\n",
      "Uniform Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.499\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.50      0.57     24645\n",
      "           1       0.34      0.50      0.41     12819\n",
      "\n",
      "    accuracy                           0.50     37464\n",
      "   macro avg       0.50      0.50      0.49     37464\n",
      "weighted avg       0.55      0.50      0.51     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[12280 12365]\n",
      " [ 6402  6417]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Dummy Classifiers\n",
      "Most Frequent Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.658\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79     24645\n",
      "           1       0.00      0.00      0.00     12819\n",
      "\n",
      "    accuracy                           0.66     37464\n",
      "   macro avg       0.33      0.50      0.40     37464\n",
      "weighted avg       0.43      0.66      0.52     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[24645     0]\n",
      " [12819     0]]\n",
      "Training Complete\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for clf, name in (\n",
    "    (DummyClassifier(strategy='uniform', random_state=RANDOM_SEED), \"Uniform Classifier\"),\n",
    "    (DummyClassifier(strategy='most_frequent', random_state=RANDOM_SEED), \"Most Frequent Classifier\"),\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results - Dummy Classifiers\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6228c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "MultinomialNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.867\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.88      0.90     24645\n",
      "           1       0.79      0.83      0.81     12819\n",
      "\n",
      "    accuracy                           0.87     37464\n",
      "   macro avg       0.85      0.86      0.85     37464\n",
      "weighted avg       0.87      0.87      0.87     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21806  2839]\n",
      " [ 2149 10670]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "BernoulliNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.832\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88     24645\n",
      "           1       0.79      0.69      0.74     12819\n",
      "\n",
      "    accuracy                           0.83     37464\n",
      "   macro avg       0.82      0.80      0.81     37464\n",
      "weighted avg       0.83      0.83      0.83     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[22322  2323]\n",
      " [ 3965  8854]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "ComplementNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.855\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.83      0.88     24645\n",
      "           1       0.73      0.91      0.81     12819\n",
      "\n",
      "    accuracy                           0.85     37464\n",
      "   macro avg       0.84      0.87      0.85     37464\n",
      "weighted avg       0.87      0.85      0.86     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[20400  4245]\n",
      " [ 1198 11621]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.870\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.86      0.90     24645\n",
      "           1       0.76      0.90      0.83     12819\n",
      "\n",
      "    accuracy                           0.87     37464\n",
      "   macro avg       0.85      0.88      0.86     37464\n",
      "weighted avg       0.88      0.87      0.87     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21083  3562]\n",
      " [ 1293 11526]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "\n",
    "for clf, name in (\n",
    "    (MultinomialNB(alpha=0.01), \"MultinomialNB\"),\n",
    "    (BernoulliNB(alpha=0.01), \"BernoulliNB\"),\n",
    "    (ComplementNB(alpha=0.1), \"ComplementNB\"),\n",
    "    (LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED), \"Logistic Regression\")\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results - Naive Bayes & LogReg\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)\n",
    "    preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7bd9b5",
   "metadata": {},
   "source": [
    "The baseline results are quite promising, with both MultinomialNB and Logistic Regression achieving 0.85 on macro F1-score. This means that the bag-of-word approach is a rather solid approach for sentiment classification. It's also interesting to see that while MultinomialNB has a rather balanced number of false pos and false neg, BernoulliNB and ComplementNB are different. BernoulliNB has a much higher number of fps, while ComplementNB has a much higher number of fns.\n",
    "\n",
    "Also, according to https://web.stanford.edu/~jurafsky/slp3/4.pdf, using binary NB (BernoulliNB) may improve predictive performance, as whether a word occurs or not seems to matter more than its frequency. But in this case, BernoulliNB does not outperform other Naive Bayes methods. We'll come back to this in a second.\n",
    "\n",
    "Let's take a look at a few of mis-classifications for both Naive Bayes and Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e6fae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for mis-classifications\n",
    "def create_mis_classification_df(name):\n",
    "    mis_class = pd.DataFrame(X_dev)\n",
    "    mis_class['Actual'] = y_dev\n",
    "    mis_class['Predicted'] = preds[name]\n",
    "    mis_class = mis_class[mis_class['Actual'] != mis_class['Predicted']]\n",
    "    return mis_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "48696732",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_class_multi = create_mis_classification_df('MultinomialNB')\n",
    "mis_class_bernoulli = create_mis_classification_df('BernoulliNB')\n",
    "mis_class_complement = create_mis_classification_df('ComplementNB')\n",
    "mis_class_logreg = create_mis_classification_df('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "83f232f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Trash app', 1, 0],\n",
       "       ['Do we need to pay as a passenger the highway tollfee here in Philippines?',\n",
       "        1, 0],\n",
       "       ['I cant view the drivers plate number in e-receipt or after drop off.',\n",
       "        0, 1],\n",
       "       ['service fees ridiculous', 0, 1],\n",
       "       ['Not working properly since 2 days', 0, 1],\n",
       "       ['All delivery price raised tooo muxh', 1, 0],\n",
       "       ['Easy to place order and get it delivered quickly', 0, 1],\n",
       "       [\"It's what it says on the tin.\", 0, 1],\n",
       "       [\"I didn't order anything\", 0, 1],\n",
       "       ['This app is too bad to have... It hangs a lot .... \"Kutti App\"',\n",
       "        1, 0]], dtype=object)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_multi.sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2b1f630c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Released for the United states but when I go to use it it tells me that my country (United states) is not supported.',\n",
       "        1, 0],\n",
       "       [\"Guys, can you make 'Saved Places' sorted alphabetically? it is hard to find saved-places because the sorting address is messed up. Also, since there are so many similar street names, when picking a new address, the address field should expand automatically down, so i don't have to always guess whether the address details is correct or not.\",\n",
       "        0, 1],\n",
       "       ['Why i cant update?', 1, 0],\n",
       "       [\"It's good but u need to put the riders contact cuz I once went to the restaurant to pick up the food myself\",\n",
       "        0, 1],\n",
       "       ['Top road safety measures', 1, 0],\n",
       "       [\"The app itself is good and they usually resolve issues quickly but I feel as though there is little done when it comes to restaurants that repeatedly have issues. For instance we really enjoy pret, but every time we've ordered from them they forget atleast one item. We always get the value of that item back but someone is repeatedly without food and yet it keeps happening. We would appreciate it if more could be done about the restaurants that give poor service.\",\n",
       "        0, 1],\n",
       "       ['Your new system is so badd!', 1, 0],\n",
       "       ['Too many pop ups and notifications, stop trying to gamify everything just let me order my food already.',\n",
       "        0, 1],\n",
       "       ['Does an alright job but could use a option to make an order for a later time of day.',\n",
       "        0, 1],\n",
       "       ['Please add a hide, and favorite resto tab for sorting preferences. Thanks. Customer service is not helpful.',\n",
       "        1, 0]], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_bernoulli.sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c0bb7438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Explore important turn off', 0, 1],\n",
       "       ['This app is very bad app this app is not working', 0, 1],\n",
       "       [\"Deliveroo not acting against the racial abuse of its employees, as well as assisting the police on an immigration raid is so far beyond heinous it's impossible to find appropriate words. To call using this service unethical would be an understatement. Even outside of that, it's clunky to use, has far too many easy to accidentally click subscription buttons, and ever-rising delivery prices.\",\n",
       "        1, 0],\n",
       "       ['Theres a bug. No options fpr the drink. Pls fix. Thanks', 0, 1],\n",
       "       ['But the workflow needs help.  Why should I need to enter my current location in if I already logged in and have an address on file?  I know I could be in a different area, but give me the option to put a saved address in as well.',\n",
       "        0, 1],\n",
       "       ['It should be 24 hrs service , there is no night restaurants like u say all are closed',\n",
       "        0, 1],\n",
       "       ['Not user friendly and customer centric app and services', 1, 0],\n",
       "       [\"Grab app doesn't function in my Handphone recently. I couldn't reinstall the app. Please help. Thank you.\",\n",
       "        0, 1],\n",
       "       ['Never get my food from this app ever', 1, 0],\n",
       "       [\"Helps you get to your destination with ease I can't use grab pay to pay for my grabfood deliveries. So much for cashless payments\",\n",
       "        1, 0]], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_complement.sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "18c31000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"Waiting time when driver have to drop off another passenger first is so off \\nthe mark that it's ridiculous. Don't sugarcoat a 15 minutes wait as 5 \\nminutes. I understand there could be traffic jams in the morning so work \\nout a system where you can get more accurate timing! Bloody hell I would've \\nreached work earlier if I took public transport. Wasted my money!\",\n",
       "        0, 1],\n",
       "       ['No option for senior citizen or PWD discount.', 1, 0],\n",
       "       ['I have been waiting since 1:30hrs and yet the order is not delivered.... I have ordered it for lunch and I got it for snacks time.... Even the customer service is not responding',\n",
       "        0, 1],\n",
       "       [\"Can't use pro vouchers. shop.checkout.voucher.validation.invalid error encountered\",\n",
       "        0, 1],\n",
       "       ['Some of my nearby restaurants are still not available.', 0, 1],\n",
       "       [\"I'm foodpanda fanâ¤ï¸â¤ï¸â¤ï¸â¤ï¸\", 0, 1],\n",
       "       ['It doesnâ€™t work with latest IOS 11', 0, 1],\n",
       "       ['Does an alright job but could use a option to make an order for a later time of day.',\n",
       "        0, 1],\n",
       "       ['Searching for food feels like a maze. Interface could be way way simpler. Need major upgrade on this regard.',\n",
       "        1, 0],\n",
       "       ['Awesom app for foodie peopleðŸ˜', 0, 1]], dtype=object)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_logreg.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa3993d",
   "metadata": {},
   "source": [
    "Really interesting. Looking at the results, there are a few cases of mis-classifications:\n",
    "- Reviews that are not in English. Presumably reviews not in English won't be as robust in terms of tokenization and vectorization. (Note: fixed now, but no obvious improvement in performance.)\n",
    "- Reviews that contain negation expressions, eg \"no good\" is classified as a positive review when in reality it should be negative. BoW approach makes it hard for ML model to recognize this kind of expressions.\n",
    "- Reviews that are mis-classified due to rating. Eg a customer may write something negative but give 3 stars. It's tricky in this case because it's a caveat of our dataset.\n",
    "- Some mis-classification is the ML model being weirdly off, eg ComplementNB classified a \"Good\" review as negative, or reviews containing the word 'hate' gets classified as positive.\n",
    "- Contextual awareness is important and this is something that bag-of-word approaches cannot address. For example the sentence 'Very good. Expensive delivery charge though' gets classified as negative likely because of the word expensive, while in reality this is a positive review."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b02b0da",
   "metadata": {},
   "source": [
    "### 2.1 Reduce min_df\n",
    "\n",
    "We set a min frequency cap of 500. What happens if we reduce this cap to 100?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3069fad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(stop_words='english', min_df=100, ngram_range=(1,2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_dev_bow = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "04437490",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "MultinomialNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.879\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.89      0.91     24645\n",
      "           1       0.80      0.87      0.83     12819\n",
      "\n",
      "    accuracy                           0.88     37464\n",
      "   macro avg       0.86      0.88      0.87     37464\n",
      "weighted avg       0.88      0.88      0.88     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21815  2830]\n",
      " [ 1697 11122]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "BernoulliNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.835\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.91      0.88     24645\n",
      "           1       0.80      0.70      0.74     12819\n",
      "\n",
      "    accuracy                           0.84     37464\n",
      "   macro avg       0.82      0.80      0.81     37464\n",
      "weighted avg       0.83      0.84      0.83     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[22346  2299]\n",
      " [ 3878  8941]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "ComplementNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.865\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.89     24645\n",
      "           1       0.74      0.92      0.82     12819\n",
      "\n",
      "    accuracy                           0.87     37464\n",
      "   macro avg       0.85      0.88      0.86     37464\n",
      "weighted avg       0.88      0.87      0.87     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[20569  4076]\n",
      " [  970 11849]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.884\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.87      0.91     24645\n",
      "           1       0.79      0.91      0.84     12819\n",
      "\n",
      "    accuracy                           0.88     37464\n",
      "   macro avg       0.87      0.89      0.88     37464\n",
      "weighted avg       0.89      0.88      0.89     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21470  3175]\n",
      " [ 1157 11662]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "\n",
    "for clf, name in (\n",
    "    (MultinomialNB(alpha=0.01), \"MultinomialNB\"),\n",
    "    (BernoulliNB(alpha=0.01), \"BernoulliNB\"),\n",
    "    (ComplementNB(alpha=0.1), \"ComplementNB\"),\n",
    "    (LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED), \"Logistic Regression\")\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results - Naive Bayes & LogReg\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)\n",
    "    preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43752fc7",
   "metadata": {},
   "source": [
    "Slight bump in performance, but at the expense of longer training time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ab34f0",
   "metadata": {},
   "source": [
    "### 2.2 Not use stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "50f0ec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=100, ngram_range=(1,2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_dev_bow = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d6e95fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "MultinomialNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.886\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.88      0.91     24645\n",
      "           1       0.80      0.90      0.84     12819\n",
      "\n",
      "    accuracy                           0.89     37464\n",
      "   macro avg       0.87      0.89      0.88     37464\n",
      "weighted avg       0.89      0.89      0.89     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21713  2932]\n",
      " [ 1343 11476]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "BernoulliNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.807\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.89      0.86     24645\n",
      "           1       0.76      0.64      0.70     12819\n",
      "\n",
      "    accuracy                           0.81     37464\n",
      "   macro avg       0.79      0.77      0.78     37464\n",
      "weighted avg       0.80      0.81      0.80     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21980  2665]\n",
      " [ 4566  8253]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "ComplementNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.874\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.90     24645\n",
      "           1       0.75      0.94      0.84     12819\n",
      "\n",
      "    accuracy                           0.87     37464\n",
      "   macro avg       0.86      0.89      0.87     37464\n",
      "weighted avg       0.89      0.87      0.88     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[20676  3969]\n",
      " [  769 12050]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.901\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92     24645\n",
      "           1       0.81      0.93      0.86     12819\n",
      "\n",
      "    accuracy                           0.90     37464\n",
      "   macro avg       0.88      0.91      0.89     37464\n",
      "weighted avg       0.91      0.90      0.90     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21809  2836]\n",
      " [  891 11928]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "\n",
    "for clf, name in (\n",
    "    (MultinomialNB(alpha=0.01), \"MultinomialNB\"),\n",
    "    (BernoulliNB(alpha=0.01), \"BernoulliNB\"),\n",
    "    (ComplementNB(alpha=0.1), \"ComplementNB\"),\n",
    "    (LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED), \"Logistic Regression\")\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results - Naive Bayes & LogReg\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)\n",
    "    preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2a19e6",
   "metadata": {},
   "source": [
    "Performance improved, surprisingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94477f7",
   "metadata": {},
   "source": [
    "### 2.3 Set max_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5c9b9614",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=100, max_df=5000, ngram_range=(1,2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_dev_bow = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "332660b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "MultinomialNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.884\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91     24645\n",
      "           1       0.82      0.85      0.83     12819\n",
      "\n",
      "    accuracy                           0.88     37464\n",
      "   macro avg       0.87      0.88      0.87     37464\n",
      "weighted avg       0.89      0.88      0.88     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[22183  2462]\n",
      " [ 1898 10921]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "BernoulliNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.814\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86     24645\n",
      "           1       0.78      0.64      0.70     12819\n",
      "\n",
      "    accuracy                           0.81     37464\n",
      "   macro avg       0.80      0.77      0.78     37464\n",
      "weighted avg       0.81      0.81      0.81     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[22291  2354]\n",
      " [ 4615  8204]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "ComplementNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.875\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.85      0.90     24645\n",
      "           1       0.76      0.92      0.83     12819\n",
      "\n",
      "    accuracy                           0.87     37464\n",
      "   macro avg       0.86      0.89      0.87     37464\n",
      "weighted avg       0.89      0.87      0.88     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21006  3639]\n",
      " [ 1048 11771]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.894\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92     24645\n",
      "           1       0.81      0.90      0.85     12819\n",
      "\n",
      "    accuracy                           0.89     37464\n",
      "   macro avg       0.88      0.90      0.89     37464\n",
      "weighted avg       0.90      0.89      0.90     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21943  2702]\n",
      " [ 1269 11550]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "\n",
    "for clf, name in (\n",
    "    (MultinomialNB(alpha=0.01), \"MultinomialNB\"),\n",
    "    (BernoulliNB(alpha=0.01), \"BernoulliNB\"),\n",
    "    (ComplementNB(alpha=0.1), \"ComplementNB\"),\n",
    "    (LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED), \"Logistic Regression\")\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results - Naive Bayes & LogReg\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)\n",
    "    preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689aa697",
   "metadata": {},
   "source": [
    "Not much changes from stopwords removal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5503bb7c",
   "metadata": {},
   "source": [
    "### 2.4 Clip frequency at 1\n",
    "\n",
    "Earlier, we see that there isn't any performance with BernoulliNB as compared to other methods. But what if we clip the frequency at the feature processing level? Luckily, sklearn tfidf has a `binary` parameters that allows us to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9936465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(binary=True, ngram_range=(1,1))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_dev_bow = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e08ddff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "MultinomialNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.871\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.88      0.90     24645\n",
      "           1       0.79      0.85      0.82     12819\n",
      "\n",
      "    accuracy                           0.87     37464\n",
      "   macro avg       0.85      0.86      0.86     37464\n",
      "weighted avg       0.87      0.87      0.87     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21782  2863]\n",
      " [ 1985 10834]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "BernoulliNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.800\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85     24645\n",
      "           1       0.74      0.64      0.69     12819\n",
      "\n",
      "    accuracy                           0.80     37464\n",
      "   macro avg       0.78      0.76      0.77     37464\n",
      "weighted avg       0.80      0.80      0.80     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21773  2872]\n",
      " [ 4630  8189]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "ComplementNB\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.864\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.89     24645\n",
      "           1       0.74      0.92      0.82     12819\n",
      "\n",
      "    accuracy                           0.86     37464\n",
      "   macro avg       0.85      0.88      0.86     37464\n",
      "weighted avg       0.88      0.86      0.87     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[20530  4115]\n",
      " [  968 11851]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results - Naive Bayes & LogReg\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.898\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92     24645\n",
      "           1       0.80      0.93      0.86     12819\n",
      "\n",
      "    accuracy                           0.90     37464\n",
      "   macro avg       0.88      0.90      0.89     37464\n",
      "weighted avg       0.91      0.90      0.90     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21766  2879]\n",
      " [  961 11858]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "\n",
    "for clf, name in (\n",
    "    (MultinomialNB(alpha=0.01), \"MultinomialNB\"),\n",
    "    (BernoulliNB(alpha=0.01), \"BernoulliNB\"),\n",
    "    (ComplementNB(alpha=0.1), \"ComplementNB\"),\n",
    "    (LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED), \"Logistic Regression\")\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results - Naive Bayes & LogReg\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)\n",
    "    preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d9835",
   "metadata": {},
   "source": [
    "### 2.5 Tune Logistic Regression Params\n",
    "\n",
    "So far, LogReg performs the best in terms of macro F1 score. In this section, we'll try tuning the performance of Logistic Regression, using the best Tfidf tuning result above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0ec767c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df=100, ngram_range=(1,2))\n",
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_dev_bow = vectorizer.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3bbdc5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LogReg Grid Search\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{'C': 1.623776739188721}\n",
      "accuracy:   0.901\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.89      0.92     24645\n",
      "           1       0.81      0.93      0.87     12819\n",
      "\n",
      "    accuracy                           0.90     37464\n",
      "   macro avg       0.88      0.91      0.89     37464\n",
      "weighted avg       0.91      0.90      0.90     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[21845  2800]\n",
      " [  911 11908]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=3000, random_state=RANDOM_SEED)\n",
    "param_grid = {'C' : np.logspace(-4, 4, 20)}\n",
    "\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LogReg Grid Search\")\n",
    "clf = GridSearchCV(clf, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(X_train_bow, y_train)\n",
    "print(clf.best_params_)\n",
    "y_dev_pred = clf.predict(X_dev_bow)\n",
    "score = accuracy_score(y_dev, y_dev_pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_dev, y_dev_pred))\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_dev, y_dev_pred))\n",
    "print(\"Training Complete\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f02387",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
