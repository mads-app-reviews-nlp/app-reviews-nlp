{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21330d8",
   "metadata": {},
   "source": [
    "## Sentiment Classification SG Reviews Data (WE, non-Deep Learning)\n",
    "\n",
    "This notebook covers two good approaches to perform sentiment classification - Naive Bayes and Logistic Regression. We will train SG reviews data on both.\n",
    "\n",
    "As a rule of thumb, reviews that are 3 stars and above are **positive**, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a09b873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /home/meln/.local/lib/python3.8/site-packages (4.1.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/meln/.local/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from gensim) (1.6.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926204c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import spacy\n",
    "import nltk\n",
    "import gensim.downloader\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from spacy.language import Language\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22215586",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 33"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06beabd4",
   "metadata": {},
   "source": [
    "We'll be reusing the SG filtered data which has excluded non-English reviews in the BOW notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1fcb6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>language</th>\n",
       "      <th>cof_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Used to be a good app been using for years, no...</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Grab app is convenient because you can use mul...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I used to love the subscription plans that the...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I ordered a grabfood and one of the 3 items ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>This platform gives too much power to restaura...</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                             review  label  \\\n",
       "0           0  Used to be a good app been using for years, no...      0   \n",
       "1           1  Grab app is convenient because you can use mul...      1   \n",
       "2           2  I used to love the subscription plans that the...      1   \n",
       "3           3  I ordered a grabfood and one of the 3 items ar...      1   \n",
       "4           4  This platform gives too much power to restaura...      1   \n",
       "\n",
       "  language  cof_score  \n",
       "0       en   0.999996  \n",
       "1       en   0.999999  \n",
       "2       en   0.999999  \n",
       "3       en   0.999998  \n",
       "4       en   0.999998  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(\"assets/reviews_sg_filtered.csv\")\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "901b33b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews.drop(columns=['Unnamed: 0', 'language', 'cof_score'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "570595bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Used to be a good app been using for years, no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grab app is convenient because you can use mul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I used to love the subscription plans that the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I ordered a grabfood and one of the 3 items ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This platform gives too much power to restaura...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  Used to be a good app been using for years, no...      0\n",
       "1  Grab app is convenient because you can use mul...      1\n",
       "2  I used to love the subscription plans that the...      1\n",
       "3  I ordered a grabfood and one of the 3 items ar...      1\n",
       "4  This platform gives too much power to restaura...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f9a3f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "374633\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb8b89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2701e569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Used to be a good app been using for years, no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Grab app is convenient because you can use mul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I used to love the subscription plans that the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I ordered a grabfood and one of the 3 items ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This platform gives too much power to restaura...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  Used to be a good app been using for years, no...      0\n",
       "1  Grab app is convenient because you can use mul...      1\n",
       "2  I used to love the subscription plans that the...      1\n",
       "3  I ordered a grabfood and one of the 3 items ar...      1\n",
       "4  This platform gives too much power to restaura...      1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc = reviews.copy()\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea35db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_proc['review']\n",
    "y = df_proc['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a246c2e",
   "metadata": {},
   "source": [
    "## 2. Train Corpus on Word2Vec Model\n",
    "\n",
    "It's unclear to me whether we should create the word2vec model on the entire corpus, or just the train dataset. From 655 class it seems the entire corpus was used, so let's give it a shot.\n",
    "\n",
    "Also referencing: https://github.com/nadbordrozd/blog_stuff/blob/master/classification_w2v/benchmarking_python3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "991c7152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/meln/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20cfe4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce4403be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 374633/374633 [00:03<00:00, 120609.41it/s]\n"
     ]
    }
   ],
   "source": [
    "all_tokenized_reviews = []\n",
    "\n",
    "for review in tqdm(X):\n",
    "    tokens = [token for token in re.findall(r'\\w+', review) if token not in stop_words]\n",
    "    all_tokenized_reviews.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69336a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = Word2Vec(sentences=all_tokenized_reviews, vector_size=100, \n",
    "                      window=2, min_count=100, workers=4, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "60c39a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.save(\"word2vec_sg.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07c6e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_kv = full_model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e23ba",
   "metadata": {},
   "source": [
    "We will split the dataset into `train`, `test`, and `dev`, with 80%, 10%, 10% ratio, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "001cc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_test, X_dev, y_test, y_dev = train_test_split(X_test, y_test, test_size=0.5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "676ca2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299706"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b338cf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37464"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e946dbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37463"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "acc8ec94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Great'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c23ad78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Food pandas have made it very easy to order food and drink.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70a46a",
   "metadata": {},
   "source": [
    "## 3. Word Embeddings Approach on Logistic Regression\n",
    "\n",
    "This section explores the use of word embeddings as feature extraction. We'll be working with dense representations of documents instead of the bag-of-words representations we used earlier. To do this, we'll use the average (or mean) word vector of a document and classify from those representations.\n",
    "\n",
    "As a first step, let's tokenize the reviews here using regular expressions. However, since we're going to be computing an average word vector, let's remove stop words. Here, we'll use NLTK's list of English stop words. Since these words shouldn't affect our classification decision, we can remove them to avoid adding any noisy they might cause. Note that all of the stopwords in NLTK's list are lower-cased, but it's possible that some stopwords in your documents are not entirely lower-cased, so they may not match without some further processing.\n",
    "\n",
    "We'll be using our corpus to train the model. We'll also be using a few of Word2Vec's pre-trained models, `word2vec-google-news-300`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "632a75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnews = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e6d721e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnews.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b239ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_small = gensim.downloader.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4c4fe50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_small.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f33fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_big = gensim.downloader.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "59205e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_big.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "350fec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dense_features(tokenized_texts, word_vectors): \n",
    "    #HINT: Create an empty list to hold your results \n",
    "        #HINT:Iterate through each item in tokenized_text\n",
    "            #HINT:Create a list that contains current item(s) if found in word_vectors\n",
    "            #HINT:if the length of this list is greater than zero:\n",
    "                #HINT:We set this as a feature, this is done by using numpy’s mean function and append it to our results list \n",
    "            #HINT:Otherwise: create a vector of numpy zeros using word_vectors.vector_size as the parameter and append it to the results list\n",
    "    #HINT:Return the results list as a numpy array (data type)\n",
    "\n",
    "    res = []\n",
    "    for token in tokenized_texts:\n",
    "        items_in_vocab = [item for item in token if item in word_vectors]\n",
    "        if len(items_in_vocab) > 0:\n",
    "            res.append(np.mean(word_vectors[items_in_vocab], axis=0))\n",
    "        else:\n",
    "            res.append(np.zeros(word_vectors.vector_size))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "64b5b8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 299706/299706 [00:02<00:00, 101077.49it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_items = []\n",
    "for review in tqdm(X_train):\n",
    "    tokens = [token for token in re.findall(r'\\w+', review) if token not in stop_words]\n",
    "    tokenized_train_items.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d4c73808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokenized_train_items[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "db1c797c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Great']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b3ed3d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37464/37464 [00:00<00:00, 145539.68it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dev_items = []\n",
    "for review in tqdm(X_dev):\n",
    "    tokens = [token for token in re.findall(r'\\w+', review) if token not in stop_words]\n",
    "    tokenized_dev_items.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "154941b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(clf):\n",
    "    print(\"_\" * 80)\n",
    "    print(\"Training: \")\n",
    "    clf.fit(X_train_wp, y_train)\n",
    "    y_dev_pred = clf.predict(X_dev_wp)\n",
    "    \n",
    "    score = accuracy_score(y_dev, y_dev_pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \n",
    "    print(\"classification report:\")\n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "    \n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(y_dev, y_dev_pred))\n",
    "    print(\"Training Complete\")\n",
    "    print()\n",
    "    \n",
    "    clf_descr = str(clf).split(\"(\")[0]\n",
    "    return clf_descr, score, y_dev_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75686f55",
   "metadata": {},
   "source": [
    "It's training time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5922e",
   "metadata": {},
   "source": [
    "### 3.1 Word2Vec on reviews corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "50fbeacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wp = generate_dense_features(tokenized_train_items, full_model_kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42935e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(299706, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_wp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0de54b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_wp = generate_dense_features(tokenized_dev_items, full_model_kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3cf8180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37464, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_dev_wp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6228c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results\n",
      "Uniform Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.499\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.50      0.57     24645\n",
      "           1       0.34      0.50      0.41     12819\n",
      "\n",
      "    accuracy                           0.50     37464\n",
      "   macro avg       0.50      0.50      0.49     37464\n",
      "weighted avg       0.55      0.50      0.51     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[12280 12365]\n",
      " [ 6402  6417]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results\n",
      "Most Frequent Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.658\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.79     24645\n",
      "           1       0.00      0.00      0.00     12819\n",
      "\n",
      "    accuracy                           0.66     37464\n",
      "   macro avg       0.33      0.50      0.40     37464\n",
      "weighted avg       0.43      0.66      0.52     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[24645     0]\n",
      " [12819     0]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.869\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89     24645\n",
      "           1       0.75      0.92      0.83     12819\n",
      "\n",
      "    accuracy                           0.87     37464\n",
      "   macro avg       0.85      0.88      0.86     37464\n",
      "weighted avg       0.88      0.87      0.87     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[20813  3832]\n",
      " [ 1066 11753]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "\n",
    "for clf, name in (\n",
    "    (DummyClassifier(strategy='uniform', random_state=RANDOM_SEED), \"Uniform Classifier\"),\n",
    "    (DummyClassifier(strategy='most_frequent', random_state=RANDOM_SEED), \"Most Frequent Classifier\"),\n",
    "    (LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED), \"Logistic Regression\")\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)\n",
    "    preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ca07e",
   "metadata": {},
   "source": [
    "Pretty good result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3e6fae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for mis-classifications\n",
    "def create_mis_classification_df(name):\n",
    "    mis_class = pd.DataFrame(X_dev)\n",
    "    mis_class['Actual'] = y_dev\n",
    "    mis_class['Predicted'] = preds[name]\n",
    "    mis_class = mis_class[mis_class['Actual'] != mis_class['Predicted']]\n",
    "    return mis_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "48696732",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_class_logreg = create_mis_classification_df('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "18c31000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['I think their systems are slow, app needs some change', 0, 1],\n",
       "       ['I have been ordering from deliveroo for around 12 months and have NEVER had a problem. Most of the time the order comes a bit quicker but never late.!',\n",
       "        0, 1],\n",
       "       [\"Didn't cover near by all restaurants sometime it does sometimes not\",\n",
       "        0, 1],\n",
       "       ['Bhai Delivery to Late night tak rakho', 0, 1],\n",
       "       ['Terrible CEO in handling Foodpanda Rider in Malaysia... So arrogant',\n",
       "        0, 1],\n",
       "       ['I like it and has now become a necessary mode of transportation but lack of competition has made it more expensive than before. Watch out for the occasional promo codes.',\n",
       "        0, 1],\n",
       "       [\"GPS never works properly, so never know when the car will arrive, guess quality and monopoly don't go together.\",\n",
       "        0, 1],\n",
       "       ['So much easy to get foods and transportation with GRAB. How about getting sea cruises and short trips around Singapore. Thanks',\n",
       "        1, 0],\n",
       "       ['Food', 1, 0],\n",
       "       ['sometime voucher cannot use or full redeemly so dispointed', 0,\n",
       "        1]], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_logreg.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb8f1fc",
   "metadata": {},
   "source": [
    "### 3.2 Google News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2261ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wp = generate_dense_features(tokenized_train_items, gnews)\n",
    "X_dev_wp = generate_dense_features(tokenized_dev_items, gnews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8e683a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.863\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.89     24645\n",
      "           1       0.74      0.92      0.82     12819\n",
      "\n",
      "    accuracy                           0.86     37464\n",
      "   macro avg       0.85      0.88      0.85     37464\n",
      "weighted avg       0.88      0.86      0.87     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[20564  4081]\n",
      " [ 1053 11766]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "print(\"=\" * 80)\n",
    "print(\"Training Results\")\n",
    "print(\"Logistic Regression\")\n",
    "clf = LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED)\n",
    "mod = train_model(clf)\n",
    "preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ef5e88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_class_logreg_gnews = create_mis_classification_df('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "281508f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[\"Couldn't add visa, amex or mastercard...\", 1, 0],\n",
       "       ['One day i was hungry in midnight and thought what to do suddenly i see an app on my f.b page first i download app than wait for 15mnt my order on my door thank a lot food panda',\n",
       "        0, 1],\n",
       "       [\"sometimes the app doesn't recognizes my address or there are some other store/restaurant that is not available the next day after you order.\",\n",
       "        0, 1],\n",
       "       ['I was forced to use this app because the competing app Z stopped working and their customer service was terrible. This app works very smoothly and with no hassles at all',\n",
       "        0, 1],\n",
       "       [\"App is good. Delivery isn't... just for my food to get to me from the place i ordered...which is literally 2 minutes away. It took 40 minutes. I have no idea what the person delivering it was doing...just going round in circles...only to go to the wrong address then say they were waiting outside the whole time...when we were watching them on the live gps going around the streets.\",\n",
       "        0, 1],\n",
       "       ['Please include Monterey on food panda mart', 1, 0],\n",
       "       ['worst apps ever', 0, 1],\n",
       "       ['Out standing', 0, 1],\n",
       "       ['Notes to driver is a very useful feature but apparently majority of the drivers are not reading it. Repeating the notes in chat everytime is very annoying.',\n",
       "        0, 1],\n",
       "       ['It is really irritating to update the app every time I use the app.',\n",
       "        0, 1]], dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_logreg_gnews.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411de11c",
   "metadata": {},
   "source": [
    "### 3.3 Glove Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bd5acf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wp = generate_dense_features(tokenized_train_items, glove_small)\n",
    "X_dev_wp = generate_dense_features(tokenized_dev_items, glove_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c3583f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.799\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.84     24645\n",
      "           1       0.67      0.83      0.74     12819\n",
      "\n",
      "    accuracy                           0.80     37464\n",
      "   macro avg       0.78      0.81      0.79     37464\n",
      "weighted avg       0.82      0.80      0.80     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[19337  5308]\n",
      " [ 2224 10595]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "print(\"=\" * 80)\n",
    "print(\"Training Results\")\n",
    "print(\"Logistic Regression\")\n",
    "clf = LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED)\n",
    "mod = train_model(clf)\n",
    "preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d329eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_class_logreg_glove_small = create_mis_classification_df('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9e4891df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Cannot located my delivery location at all', 1, 0],\n",
       "       [\"Yasmin to a few weeks ago but the UK to the season with salt in my love. The new one for a bit late but it's still available on a few weeks back on Monday and the rest of the\",\n",
       "        0, 1],\n",
       "       ['What happened to money transfer?', 0, 1],\n",
       "       ['dear developer why prepaid top up cannot be used?', 0, 1],\n",
       "       [\"Hopefully the driver finds our address this time, they haven't on the last 8 orders. ( not holding my breath). Driver's never read the delivery notes.\",\n",
       "        0, 1],\n",
       "       ['Should allow history of riders, drivers and restaurants so feedback / rating / tips can be given after giving them some thought on the quality of service / satisfaction level (rather than having to respond almost immediately after the transaction)',\n",
       "        0, 1],\n",
       "       ['Cannot change number and no other log in ways', 1, 0],\n",
       "       ['Stupid Service', 1, 0],\n",
       "       ['Easy to order.', 0, 1],\n",
       "       ['Almost no bugs. Runs very smoothly', 0, 1]], dtype=object)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_logreg_glove_small.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f85773",
   "metadata": {},
   "source": [
    "### 3.4 Glove Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de0f0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wp = generate_dense_features(tokenized_train_items, glove_big)\n",
    "X_dev_wp = generate_dense_features(tokenized_dev_items, glove_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3e78bd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.821\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.81      0.86     24645\n",
      "           1       0.69      0.85      0.76     12819\n",
      "\n",
      "    accuracy                           0.82     37464\n",
      "   macro avg       0.80      0.83      0.81     37464\n",
      "weighted avg       0.84      0.82      0.82     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[19857  4788]\n",
      " [ 1926 10893]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "print(\"=\" * 80)\n",
    "print(\"Training Results\")\n",
    "print(\"Logistic Regression\")\n",
    "clf = LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED)\n",
    "mod = train_model(clf)\n",
    "preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55cec0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_class_logreg_glove_big = create_mis_classification_df('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99fbb4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['They need more improvement this app', 1, 0],\n",
       "       ['I really like this app. I use it almost every weekend and never been disappointed. Thanks food panda team for this app..',\n",
       "        0, 1],\n",
       "       ['lund app h mc bc', 1, 0],\n",
       "       [\"Problem.... Apps... I don't know how to track my order... No contact no.... And contact number appear fake....\",\n",
       "        0, 1],\n",
       "       ['When will you guys begin services in Poipet City, Cambodia?', 0,\n",
       "        1],\n",
       "       ['I have been using deliveroo for years without any issues', 0, 1],\n",
       "       ['Disgut this app', 1, 0],\n",
       "       [\"Great interface as it is very user friendly. Saving of address is also very intuitive. Edit: Recently, the app has gone to the dumps. Plus, no one cares what your order is delayed / cancelled by the vendors. Foodpanda just promises to refund you 'soon'. I'm not sure how that will help me feed my elderly parents who were waiting for dinner only for it to be cancelled only after half hour of waiting. Recommendation : It would be faster to wait for a taxi to bring you to a physical store to buy your food.\",\n",
       "        0, 1],\n",
       "       ['Best app but just little problem any help line cal number not show there',\n",
       "        0, 1],\n",
       "       [\"Since 2020, this app always crash and need to reinstall everytime want to use it... That's only for one time use only.. Please fix this before add any other miscellaneous features..\",\n",
       "        1, 0]], dtype=object)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_logreg_glove_big.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e138d765",
   "metadata": {},
   "source": [
    "### 3.5 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b029ad3c",
   "metadata": {},
   "source": [
    "Perhaps unsurprisingly, the model achieved the highest macro average F1-score on the Word2Vec model trained using the reviews corpus. However, it's also striking to see that pre-trained Word2Vec models did just as well. Gnews for example, achieved a F1-score of 0.87, while Glove Big achieved 0.84. While this is still inferior to the bag-of-words approach, it shows just how effective the word embeddings method can be.\n",
    "\n",
    "Unfortunately, it is a lot harder to understand the mis-classifications. Except for those reviews where the rating given isn't an accurate reflection of the sentiment, it's hard to understand the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d9835",
   "metadata": {},
   "source": [
    "### 3.6 Tune Logistic Regression Params\n",
    "\n",
    "We'll try tuning Logistic Regression C parameter again, similar to BOW. I really like the fact that Google News embeddings did so well, so let's use that as the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9c99d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wp = generate_dense_features(tokenized_train_items, gnews)\n",
    "X_dev_wp = generate_dense_features(tokenized_dev_items, gnews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3bbdc5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LogReg Grid Search\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{'C': 1438.44988828766}\n",
      "accuracy:   0.863\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.89     24645\n",
      "           1       0.74      0.92      0.82     12819\n",
      "\n",
      "    accuracy                           0.86     37464\n",
      "   macro avg       0.85      0.88      0.86     37464\n",
      "weighted avg       0.88      0.86      0.87     37464\n",
      "\n",
      "confusion matrix:\n",
      "[[20577  4068]\n",
      " [ 1058 11761]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=3000, random_state=RANDOM_SEED)\n",
    "param_grid = {'C' : np.logspace(-4, 4, 20)}\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LogReg Grid Search\")\n",
    "clf = GridSearchCV(clf, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(X_train_wp, y_train)\n",
    "print(clf.best_params_)\n",
    "y_dev_pred = best_clf.predict(X_dev_wp)\n",
    "score = accuracy_score(y_dev, y_dev_pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_dev, y_dev_pred))\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_dev, y_dev_pred))\n",
    "print(\"Training Complete\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b67a1",
   "metadata": {},
   "source": [
    "## 4. Running on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "88f02387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37463/37463 [00:00<00:00, 118152.38it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_test_items = []\n",
    "for review in tqdm(X_test):\n",
    "    tokens = [token for token in re.findall(r'\\w+', review) if token not in stop_words]\n",
    "    tokenized_test_items.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9608daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_wp = generate_dense_features(tokenized_test_items, gnews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bbc5e226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.865\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89     24612\n",
      "           1       0.75      0.92      0.82     12851\n",
      "\n",
      "    accuracy                           0.86     37463\n",
      "   macro avg       0.85      0.88      0.86     37463\n",
      "weighted avg       0.88      0.86      0.87     37463\n",
      "\n",
      "confusion matrix:\n",
      "[[20568  4044]\n",
      " [ 1026 11825]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_clf.predict(X_test_wp)\n",
    "score = accuracy_score(y_test, y_test_pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Training Complete\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "53ae7b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1438.44988828766}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fdd3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
