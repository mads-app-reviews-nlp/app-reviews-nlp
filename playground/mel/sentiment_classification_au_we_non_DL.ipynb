{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a21330d8",
   "metadata": {},
   "source": [
    "## Sentiment Classification AU Reviews Data (WE, non-Deep Learning)\n",
    "\n",
    "This notebook covers two good approaches to perform sentiment classification - Naive Bayes and Logistic Regression. We will train AU reviews data on both.\n",
    "\n",
    "As a rule of thumb, reviews that are 3 stars and above are **positive**, and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a09b873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /home/meln/.local/lib/python3.8/site-packages (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from gensim) (1.6.2)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages (from gensim) (1.20.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /home/meln/.local/lib/python3.8/site-packages (from gensim) (5.2.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "926204c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re\n",
    "import random\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "import spacy\n",
    "import nltk\n",
    "import gensim.downloader\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, ComplementNB, MultinomialNB\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from spacy.language import Language\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22215586",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1fcb6d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-11</td>\n",
       "      <td>Iâ€™ve been a DoorDash user for a while now and ...</td>\n",
       "      <td>3</td>\n",
       "      <td>DoorDash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>I ordered a meal for delivery and after 1:30 I...</td>\n",
       "      <td>1</td>\n",
       "      <td>DoorDash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>I have gotten three orders from Doordash, all ...</td>\n",
       "      <td>1</td>\n",
       "      <td>DoorDash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>The delay and customer support I experienced w...</td>\n",
       "      <td>1</td>\n",
       "      <td>DoorDash</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>I have had countless problems using DoorDash s...</td>\n",
       "      <td>1</td>\n",
       "      <td>DoorDash</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             review  rating  \\\n",
       "0  2020-07-11  Iâ€™ve been a DoorDash user for a while now and ...       3   \n",
       "1  2020-05-26  I ordered a meal for delivery and after 1:30 I...       1   \n",
       "2  2020-09-03  I have gotten three orders from Doordash, all ...       1   \n",
       "3  2021-08-13  The delay and customer support I experienced w...       1   \n",
       "4  2021-11-01  I have had countless problems using DoorDash s...       1   \n",
       "\n",
       "        app  \n",
       "0  DoorDash  \n",
       "1  DoorDash  \n",
       "2  DoorDash  \n",
       "3  DoorDash  \n",
       "4  DoorDash  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_pickle(\"assets/au_reviews.pkl\")\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49be95aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['label'] = np.where(reviews['rating'] >= 3, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "570595bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>app</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-07-11</td>\n",
       "      <td>Iâ€™ve been a DoorDash user for a while now and ...</td>\n",
       "      <td>3</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-26</td>\n",
       "      <td>I ordered a meal for delivery and after 1:30 I...</td>\n",
       "      <td>1</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>I have gotten three orders from Doordash, all ...</td>\n",
       "      <td>1</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-08-13</td>\n",
       "      <td>The delay and customer support I experienced w...</td>\n",
       "      <td>1</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>I have had countless problems using DoorDash s...</td>\n",
       "      <td>1</td>\n",
       "      <td>DoorDash</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             review  rating  \\\n",
       "0  2020-07-11  Iâ€™ve been a DoorDash user for a while now and ...       3   \n",
       "1  2020-05-26  I ordered a meal for delivery and after 1:30 I...       1   \n",
       "2  2020-09-03  I have gotten three orders from Doordash, all ...       1   \n",
       "3  2021-08-13  The delay and customer support I experienced w...       1   \n",
       "4  2021-11-01  I have had countless problems using DoorDash s...       1   \n",
       "\n",
       "        app  label  \n",
       "0  DoorDash      0  \n",
       "1  DoorDash      1  \n",
       "2  DoorDash      1  \n",
       "3  DoorDash      1  \n",
       "4  DoorDash      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae770f7",
   "metadata": {},
   "source": [
    "## 1. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f956a36",
   "metadata": {},
   "source": [
    "Check the dataset size:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f9a3f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "626377\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e629cae",
   "metadata": {},
   "source": [
    "And the type of apps:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64d82e2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DoorDash', 'UberEats', 'Deliveroo', 'MenuLog', 'Grubhub']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_list = list(reviews['app'].unique())\n",
    "app_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1180a133",
   "metadata": {},
   "source": [
    "Let's also get a sense of our dataset's balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5fd33ccb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.662462\n",
       "1    0.337538\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1feda2f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.760423\n",
      "1    0.239577\n",
      "Name: label, dtype: float64\n",
      "0    0.648032\n",
      "1    0.351968\n",
      "Name: label, dtype: float64\n",
      "0    0.651189\n",
      "1    0.348811\n",
      "Name: label, dtype: float64\n",
      "0    0.682461\n",
      "1    0.317539\n",
      "Name: label, dtype: float64\n",
      "0    0.56053\n",
      "1    0.43947\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# By app\n",
    "\n",
    "for app in app_list:\n",
    "    print(reviews[reviews['app'] == app]['label'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a556a3",
   "metadata": {},
   "source": [
    "Across the board the distribution of positive and negative reviews are quite consistent between the apps. Overall, there's an imbalance in our dataset, with positive reviews making for 75% of the dataset. Let's also check for null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd9c2c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date       0\n",
       "review    54\n",
       "rating     0\n",
       "app        0\n",
       "label      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb8b89d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2701e569",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iâ€™ve been a DoorDash user for a while now and ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I ordered a meal for delivery and after 1:30 I...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have gotten three orders from Doordash, all ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The delay and customer support I experienced w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have had countless problems using DoorDash s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  Iâ€™ve been a DoorDash user for a while now and ...      0\n",
       "1  I ordered a meal for delivery and after 1:30 I...      1\n",
       "2  I have gotten three orders from Doordash, all ...      1\n",
       "3  The delay and customer support I experienced w...      1\n",
       "4  I have had countless problems using DoorDash s...      1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_proc = reviews.copy()\n",
    "df_proc.drop(columns=['date', 'rating', 'app'], inplace=True)\n",
    "df_proc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea35db64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_proc['review']\n",
    "y = df_proc['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a246c2e",
   "metadata": {},
   "source": [
    "## 2. Train Corpus on Word2Vec Model\n",
    "\n",
    "It's unclear to me whether we should create the word2vec model on the entire corpus, or just the train dataset. From 655 class it seems the entire corpus was used, so let's give it a shot.\n",
    "\n",
    "Also referencing: https://github.com/nadbordrozd/blog_stuff/blob/master/classification_w2v/benchmarking_python3.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "991c7152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/meln/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20cfe4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.geeksforgeeks.org/removing-stop-words-nltk-python/\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce4403be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 626323/626323 [00:05<00:00, 110167.67it/s]\n"
     ]
    }
   ],
   "source": [
    "all_tokenized_reviews = []\n",
    "\n",
    "for review in tqdm(X):\n",
    "    tokens = [token for token in re.findall(r'\\w+', review) if token not in stop_words]\n",
    "    all_tokenized_reviews.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69336a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = Word2Vec(sentences=all_tokenized_reviews, vector_size=100, \n",
    "                      window=2, min_count=100, workers=4, seed=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "60c39a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model.save(\"word2vec_au.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07c6e928",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_kv = full_model.wv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563e23ba",
   "metadata": {},
   "source": [
    "We will split the dataset into `train`, `test`, and `dev`, with 80%, 10%, 10% ratio, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "001cc74c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)\n",
    "X_test, X_dev, y_test, y_dev = train_test_split(X_test, y_test, test_size=0.5, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "676ca2bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "501058"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b338cf87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62633"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e946dbd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62632"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "acc8ec94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Nice apk but some restaurants supply bad quality food'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0c23ad78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dope food app'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc70a46a",
   "metadata": {},
   "source": [
    "## 3. Word Embeddings Approach on Logistic Regression\n",
    "\n",
    "This section explores the use of word embeddings as feature extraction. We'll be working with dense representations of documents instead of the bag-of-words representations we used earlier. To do this, we'll use the average (or mean) word vector of a document and classify from those representations.\n",
    "\n",
    "As a first step, let's tokenize the reviews here using regular expressions. However, since we're going to be computing an average word vector, let's remove stop words. Here, we'll use NLTK's list of English stop words. Since these words shouldn't affect our classification decision, we can remove them to avoid adding any noisy they might cause. Note that all of the stopwords in NLTK's list are lower-cased, but it's possible that some stopwords in your documents are not entirely lower-cased, so they may not match without some further processing.\n",
    "\n",
    "We'll be using our corpus to train the model. We'll also be using a few of Word2Vec's pre-trained models, `word2vec-google-news-300`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "632a75cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gnews = gensim.downloader.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6d721e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnews.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b239ccab",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_small = gensim.downloader.load('glove-wiki-gigaword-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4c4fe50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_small.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f33fa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_big = gensim.downloader.load('glove-wiki-gigaword-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "59205e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove_big.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "350fec8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dense_features(tokenized_texts, word_vectors): \n",
    "    #HINT: Create an empty list to hold your results \n",
    "        #HINT:Iterate through each item in tokenized_text\n",
    "            #HINT:Create a list that contains current item(s) if found in word_vectors\n",
    "            #HINT:if the length of this list is greater than zero:\n",
    "                #HINT:We set this as a feature, this is done by using numpyâ€™s mean function and append it to our results list \n",
    "            #HINT:Otherwise: create a vector of numpy zeros using word_vectors.vector_size as the parameter and append it to the results list\n",
    "    #HINT:Return the results list as a numpy array (data type)\n",
    "\n",
    "    res = []\n",
    "    for token in tokenized_texts:\n",
    "        items_in_vocab = [item for item in token if item in word_vectors]\n",
    "        if len(items_in_vocab) > 0:\n",
    "            res.append(np.mean(word_vectors[items_in_vocab], axis=0))\n",
    "        else:\n",
    "            res.append(np.zeros(word_vectors.vector_size))\n",
    "    return np.array(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "64b5b8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 501058/501058 [00:04<00:00, 100296.93it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_train_items = []\n",
    "for review in tqdm(X_train):\n",
    "    tokens = [token for token in re.findall(r'\\w+', review) if token not in stop_words]\n",
    "    tokenized_train_items.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4c73808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(tokenized_train_items[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db1c797c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Nice', 'apk', 'restaurants', 'supply', 'bad', 'quality', 'food']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_train_items[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3ed3d5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62633/62633 [00:00<00:00, 136772.80it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dev_items = []\n",
    "for review in tqdm(X_dev):\n",
    "    tokens = [token for token in re.findall(r'\\w+', review) if token not in stop_words]\n",
    "    tokenized_dev_items.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "154941b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(clf):\n",
    "    print(\"_\" * 80)\n",
    "    print(\"Training: \")\n",
    "    clf.fit(X_train_wp, y_train)\n",
    "    y_dev_pred = clf.predict(X_dev_wp)\n",
    "    \n",
    "    score = accuracy_score(y_dev, y_dev_pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "    \n",
    "    print(\"classification report:\")\n",
    "    print(classification_report(y_dev, y_dev_pred))\n",
    "    \n",
    "    print(\"confusion matrix:\")\n",
    "    print(confusion_matrix(y_dev, y_dev_pred))\n",
    "    print(\"Training Complete\")\n",
    "    print()\n",
    "    \n",
    "    clf_descr = str(clf).split(\"(\")[0]\n",
    "    return clf_descr, score, y_dev_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75686f55",
   "metadata": {},
   "source": [
    "It's training time!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad5922e",
   "metadata": {},
   "source": [
    "### 3.1 Word2Vec on reviews corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "50fbeacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wp = generate_dense_features(tokenized_train_items, full_model_kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "42935e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(501058, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_wp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0de54b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_wp = generate_dense_features(tokenized_dev_items, full_model_kv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c3cf8180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(62633, 100)\n"
     ]
    }
   ],
   "source": [
    "print(X_dev_wp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6228c315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results\n",
      "Uniform Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.499\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.50      0.57     41413\n",
      "           1       0.34      0.50      0.40     21220\n",
      "\n",
      "    accuracy                           0.50     62633\n",
      "   macro avg       0.50      0.50      0.49     62633\n",
      "weighted avg       0.55      0.50      0.51     62633\n",
      "\n",
      "confusion matrix:\n",
      "[[20678 20735]\n",
      " [10627 10593]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results\n",
      "Most Frequent Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.661\n",
      "classification report:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/sw/arcts/centos7/python3.8-anaconda/2021.05/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      1.00      0.80     41413\n",
      "           1       0.00      0.00      0.00     21220\n",
      "\n",
      "    accuracy                           0.66     62633\n",
      "   macro avg       0.33      0.50      0.40     62633\n",
      "weighted avg       0.44      0.66      0.53     62633\n",
      "\n",
      "confusion matrix:\n",
      "[[41413     0]\n",
      " [21220     0]]\n",
      "Training Complete\n",
      "\n",
      "================================================================================\n",
      "Training Results\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.890\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.87      0.91     41413\n",
      "           1       0.79      0.93      0.85     21220\n",
      "\n",
      "    accuracy                           0.89     62633\n",
      "   macro avg       0.87      0.90      0.88     62633\n",
      "weighted avg       0.90      0.89      0.89     62633\n",
      "\n",
      "confusion matrix:\n",
      "[[36029  5384]\n",
      " [ 1487 19733]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "\n",
    "for clf, name in (\n",
    "    (DummyClassifier(strategy='uniform', random_state=RANDOM_SEED), \"Uniform Classifier\"),\n",
    "    (DummyClassifier(strategy='most_frequent', random_state=RANDOM_SEED), \"Most Frequent Classifier\"),\n",
    "    (LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED), \"Logistic Regression\")\n",
    "):\n",
    "    print(\"=\" * 80)\n",
    "    print(\"Training Results\")\n",
    "    print(name)\n",
    "    mod = train_model(clf)\n",
    "    preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f01ca07e",
   "metadata": {},
   "source": [
    "Pretty good result!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3e6fae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for mis-classifications\n",
    "def create_mis_classification_df(name):\n",
    "    mis_class = pd.DataFrame(X_dev)\n",
    "    mis_class['Actual'] = y_dev\n",
    "    mis_class['Predicted'] = preds[name]\n",
    "    mis_class = mis_class[mis_class['Actual'] != mis_class['Predicted']]\n",
    "    return mis_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48696732",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_class_logreg = create_mis_classification_df('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "18c31000",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['But they should live chat like zomato does U have any valid number to call',\n",
       "        0, 1],\n",
       "       ['Customer helpfull', 0, 1],\n",
       "       ['Ghatiya app not useful', 1, 0],\n",
       "       ['Would rate 5 if they added Google pay as an option.', 0, 1],\n",
       "       ['i have a trouble to login with my number only', 0, 1],\n",
       "       ['Great app but super expensive.', 1, 0],\n",
       "       [\"Door dash sucks but I'm hungry and lazy so take my money you pigs\",\n",
       "        1, 0],\n",
       "       ['Que tal dar condiÃ§Ãµes DECENTES aos trabalhadores?', 1, 0],\n",
       "       [\"Very convenient way to get delivery. My only complaint is that you have to tip the dasher before they even deliver. I haven't had many bad experiences but when I have, the dasher was already tipped 18%. Also, add a custom tip option. 15% is for a waiter. 15% is the lowest tip option, which is fine when ordering for one, when ordering 100 dollars or more of food for a guy to drive five minutes up the road and get 18% it gets a little over the top.\",\n",
       "        0, 1],\n",
       "       ['OKAY', 1, 0]], dtype=object)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_logreg.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb8f1fc",
   "metadata": {},
   "source": [
    "### 3.2 Google News"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d2261ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wp = generate_dense_features(tokenized_train_items, gnews)\n",
    "X_dev_wp = generate_dense_features(tokenized_dev_items, gnews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b8e683a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.879\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90     41413\n",
      "           1       0.77      0.93      0.84     21220\n",
      "\n",
      "    accuracy                           0.88     62633\n",
      "   macro avg       0.86      0.89      0.87     62633\n",
      "weighted avg       0.89      0.88      0.88     62633\n",
      "\n",
      "confusion matrix:\n",
      "[[35404  6009]\n",
      " [ 1570 19650]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "print(\"=\" * 80)\n",
    "print(\"Training Results\")\n",
    "print(\"Logistic Regression\")\n",
    "clf = LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED)\n",
    "mod = train_model(clf)\n",
    "preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef5e88ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_class_logreg_gnews = create_mis_classification_df('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "281508f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Some options like cancel could be clearer their support service has dropped since first started',\n",
       "        0, 1],\n",
       "       [\"It's an OK app the only thing is when I order a McDonald's the food it's always mostly cold otherwise I would give 5 starts\",\n",
       "        0, 1],\n",
       "       [\"Not sure why deliveroo charged me 300 fils when I scanned my card for setting up payment method, no disclaimer was mentioned before this. Apart from that the app navigation and usuage is easy and user friendly. But I definitely didn't like to be charged for something I wasnt aware off or reason why.\",\n",
       "        0, 1],\n",
       "       [\"Some places don't care and get the orders wrong just because they don't read the order. It's frustrating. It's not the app or the drivers fault.\",\n",
       "        0, 1],\n",
       "       [\"Can't order some food in the menu.\", 0, 1],\n",
       "       [\"The customer service isn't very good\", 1, 0],\n",
       "       ['It wonâ€™t let me add my card and it says they allow commonwealth bank cards but every time I go to save it it just says thereâ€™s a problem with adding your card',\n",
       "        0, 1],\n",
       "       ['First time. Not to bad', 0, 1],\n",
       "       ['It works very well, except I cant remove my payment methods and unfortunately it declines my card even when I have money on it.',\n",
       "        0, 1],\n",
       "       ['I donâ€™t use my kitchen anymore', 0, 1]], dtype=object)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_logreg_gnews.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411de11c",
   "metadata": {},
   "source": [
    "### 3.3 Glove Small"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bd5acf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wp = generate_dense_features(tokenized_train_items, glove_small)\n",
    "X_dev_wp = generate_dense_features(tokenized_dev_items, glove_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c3583f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.826\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.81      0.86     41413\n",
      "           1       0.70      0.86      0.77     21220\n",
      "\n",
      "    accuracy                           0.83     62633\n",
      "   macro avg       0.81      0.84      0.82     62633\n",
      "weighted avg       0.84      0.83      0.83     62633\n",
      "\n",
      "confusion matrix:\n",
      "[[33424  7989]\n",
      " [ 2893 18327]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "print(\"=\" * 80)\n",
    "print(\"Training Results\")\n",
    "print(\"Logistic Regression\")\n",
    "clf = LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED)\n",
    "mod = train_model(clf)\n",
    "preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d329eac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_class_logreg_glove_small = create_mis_classification_df('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9e4891df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Yes of course, anything that will help others, teach kids, bring people and communities together . It will only be good for us everyone...',\n",
       "        0, 1],\n",
       "       ['Excellent user friendly, accurate', 0, 1],\n",
       "       ['Awesome food del app', 0, 1],\n",
       "       ['Bad', 1, 0],\n",
       "       ['Not been able to use at all yet as will not accept payment card with mo explanation as to why.',\n",
       "        0, 1],\n",
       "       ['No complaints here, never had a bad experience with uber eats',\n",
       "        0, 1],\n",
       "       ['Never had a problem with the app itself. Easy to understand ordering process. Love that I get rewards for some orders.',\n",
       "        0, 1],\n",
       "       ['can never checkout with eats. straught forward ordering with deliveroo. 1st time user',\n",
       "        0, 1],\n",
       "       [\"Good but I'd like to be able to take my card off of the app as it says you cannot delete your only active.\",\n",
       "        0, 1],\n",
       "       ['The app makes me log in every single time I open it ðŸ¤¨', 0, 1]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_logreg_glove_small.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f85773",
   "metadata": {},
   "source": [
    "### 3.4 Glove Large"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "de0f0e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wp = generate_dense_features(tokenized_train_items, glove_big)\n",
    "X_dev_wp = generate_dense_features(tokenized_dev_items, glove_big)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3e78bd82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Training Results\n",
      "Logistic Regression\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "accuracy:   0.849\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.83      0.88     41413\n",
      "           1       0.73      0.88      0.80     21220\n",
      "\n",
      "    accuracy                           0.85     62633\n",
      "   macro avg       0.83      0.86      0.84     62633\n",
      "weighted avg       0.86      0.85      0.85     62633\n",
      "\n",
      "confusion matrix:\n",
      "[[34405  7008]\n",
      " [ 2477 18743]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds = {} # A dict to store our dev set predictions\n",
    "print(\"=\" * 80)\n",
    "print(\"Training Results\")\n",
    "print(\"Logistic Regression\")\n",
    "clf = LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=1000, random_state=RANDOM_SEED)\n",
    "mod = train_model(clf)\n",
    "preds[name] = mod[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "55cec0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mis_class_logreg_glove_big = create_mis_classification_df('Logistic Regression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "99fbb4a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['Cancel order not available and all systems manually reading after step following .. other app to different...',\n",
       "        0, 1],\n",
       "       ['I like being able to track the orders. Not a huge fan of the fact that half the time drivers on bicycles end up being different people in cars but I live inWest Philly so whatever.',\n",
       "        0, 1],\n",
       "       ['Bad', 1, 0],\n",
       "       ['Best app on my phone. Feed me!', 0, 1],\n",
       "       ['Always prompt never late', 0, 1],\n",
       "       ['Not what expected to be and not to polite. Slow...Too many ads cost too much rather use local treats!',\n",
       "        1, 0],\n",
       "       [\"Was really impressed with their customer service. One thing to note, if you are trying to reschedule a delivery let them know what timezone you are in - to make it easier for them. Also, they were super helpful when I couldn't place a tip (I had an old version on the app). They manually entered the tip for me.\",\n",
       "        0, 1],\n",
       "       ['Excelente app para entrega de comida. En estos tiempos de emergencia sanitaria son lo mejor. Gracias.',\n",
       "        0, 1],\n",
       "       ['Great placeðŸ‘ðŸ‘', 0, 1],\n",
       "       ['On the fence , might need to improve on quality assurance', 1,\n",
       "        0]], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mis_class_logreg_glove_big.sample(10).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e138d765",
   "metadata": {},
   "source": [
    "### 3.5 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b029ad3c",
   "metadata": {},
   "source": [
    "Perhaps unsurprisingly, the model achieved the highest macro average F1-score on the Word2Vec model trained using the reviews corpus. However, it's also striking to see that pre-trained Word2Vec models did just as well. Gnews for example, achieved a F1-score of 0.87, while Glove Big achieved 0.84. While this is still inferior to the bag-of-words approach, it shows just how effective the word embeddings method can be.\n",
    "\n",
    "Unfortunately, it is a lot harder to understand the mis-classifications. Except for those reviews where the rating given isn't an accurate reflection of the sentiment, it's hard to understand the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8d9835",
   "metadata": {},
   "source": [
    "### 3.6 Tune Logistic Regression Params\n",
    "\n",
    "We'll try tuning Logistic Regression C parameter again, similar to BOW. I really like the fact that Google News embeddings did so well, so let's use that as the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9c99d50a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_wp = generate_dense_features(tokenized_train_items, gnews)\n",
    "X_dev_wp = generate_dense_features(tokenized_dev_items, gnews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3bbdc5fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LogReg Grid Search\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "{'C': 78.47599703514607}\n",
      "accuracy:   0.879\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.86      0.90     41413\n",
      "           1       0.77      0.93      0.84     21220\n",
      "\n",
      "    accuracy                           0.88     62633\n",
      "   macro avg       0.86      0.89      0.87     62633\n",
      "weighted avg       0.89      0.88      0.88     62633\n",
      "\n",
      "confusion matrix:\n",
      "[[35426  5987]\n",
      " [ 1572 19648]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs', class_weight='balanced', max_iter=3000, random_state=RANDOM_SEED)\n",
    "\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"LogReg Grid Search\")\n",
    "clf = GridSearchCV(clf, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(X_train_wp, y_train)\n",
    "print(clf.best_params_)\n",
    "y_dev_pred = best_clf.predict(X_dev_wp)\n",
    "score = accuracy_score(y_dev, y_dev_pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_dev, y_dev_pred))\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_dev, y_dev_pred))\n",
    "print(\"Training Complete\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba3b67a1",
   "metadata": {},
   "source": [
    "## 4. Running on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "88f02387",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62632/62632 [00:00<00:00, 101958.08it/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_test_items = []\n",
    "for review in tqdm(X_test):\n",
    "    tokens = [token for token in re.findall(r'\\w+', review) if token not in stop_words]\n",
    "    tokenized_test_items.append(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9608daea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_wp = generate_dense_features(tokenized_test_items, gnews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "bbc5e226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:   0.877\n",
      "classification report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.85      0.90     41472\n",
      "           1       0.76      0.92      0.84     21160\n",
      "\n",
      "    accuracy                           0.88     62632\n",
      "   macro avg       0.86      0.89      0.87     62632\n",
      "weighted avg       0.89      0.88      0.88     62632\n",
      "\n",
      "confusion matrix:\n",
      "[[35346  6126]\n",
      " [ 1594 19566]]\n",
      "Training Complete\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = best_clf.predict(X_test_wp)\n",
    "score = accuracy_score(y_test, y_test_pred)\n",
    "print(\"accuracy:   %0.3f\" % score)\n",
    "print(\"classification report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"confusion matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"Training Complete\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53ae7b8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 78.47599703514607}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fdd3f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
