{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "corporate-navigator",
   "metadata": {},
   "source": [
    "# Sentiment Analysis - DecisionTree, RandomForest & SVC\n",
    "\n",
    "### Import Library and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "interpreted-saudi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 636 kB 25.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /opt/conda/lib/python3.7/site-packages (from textblob) (3.4.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from nltk>=3.1->textblob) (1.15.0)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.17.1\n",
      "[nltk_data] Downloading package brown to /opt/conda/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/brown.zip.\n",
      "[nltk_data] Downloading package punkt to /opt/conda/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /opt/conda/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /opt/conda/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "Finished.\n",
      "Collecting langdetect\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 981 kB 20.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from langdetect) (1.15.0)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993221 sha256=bfa17b9b7d08435789249d9b408da794855c61b63b9fe68310df22cf657074a0\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/c5/96/8a/f90c59ed25d75e50a8c10a1b1c2d4c402e4dacfa87f3aff36a\n",
      "Successfully built langdetect\n",
      "Installing collected packages: langdetect\n",
      "Successfully installed langdetect-1.0.9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import collections\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "#import wordcloud\n",
    "import re\n",
    "import nltk\n",
    "#import langdetect \n",
    "! pip install -U textblob\n",
    "! python -m textblob.download_corpora lite\n",
    "from textblob import TextBlob\n",
    "from sklearn import feature_extraction, manifold\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#import gensim.downloader as gensim_api\n",
    "#import gensim\n",
    "from sklearn.model_selection import train_test_split\n",
    "! pip install langdetect\n",
    "from langdetect import detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "norman-washer",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomState = 233"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "minor-brush",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pickle5\n",
      "  Downloading pickle5-0.0.12-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (256 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 256 kB 23.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pickle5\n",
      "Successfully installed pickle5-0.0.12\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pickle5\n",
    "import pickle5 as pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fiscal-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Data/sg_reviews.pkl\", \"rb\") as fh:\n",
    "    raw_df = pickle.load(fh) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fifty-cisco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nwith open(\"Data/au_reviews.pkl\", \"rb\") as fh:\\n    raw_df = pickle.load(fh) \\n    '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Uncomment for Australia market data\n",
    "'''\n",
    "with open(\"Data/au_reviews.pkl\", \"rb\") as fh:\n",
    "    raw_df = pickle.load(fh) \n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "offshore-banking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>app</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>Used to be a good app been using for years, no...</td>\n",
       "      <td>5</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-08-21</td>\n",
       "      <td>Grab app is convenient because you can use mul...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-11-18</td>\n",
       "      <td>I used to love the subscription plans that the...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-11-06</td>\n",
       "      <td>I ordered a grabfood and one of the 3 items ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-09-26</td>\n",
       "      <td>This platform gives too much power to restaura...</td>\n",
       "      <td>1</td>\n",
       "      <td>GrabFood</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date                                             review  rating  \\\n",
       "0  2020-09-30  Used to be a good app been using for years, no...       5   \n",
       "1  2020-08-21  Grab app is convenient because you can use mul...       1   \n",
       "2  2020-11-18  I used to love the subscription plans that the...       1   \n",
       "3  2021-11-06  I ordered a grabfood and one of the 3 items ar...       1   \n",
       "4  2021-09-26  This platform gives too much power to restaura...       1   \n",
       "\n",
       "        app  \n",
       "0  GrabFood  \n",
       "1  GrabFood  \n",
       "2  GrabFood  \n",
       "3  GrabFood  \n",
       "4  GrabFood  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abandoned-tracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.dropna(subset=['review', 'rating'],inplace=True)\n",
    "\n",
    "raw_df = raw_df[['review','rating']]\n",
    "raw_df.loc[raw_df['rating']>2,'label'] = 'positive' \n",
    "raw_df.loc[raw_df['rating']<3,'label'] = 'negative'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collaborative-opera",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "broken-football",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there is any alphabetics in a string\n",
    "\n",
    "def check_letter(string):\n",
    "    for c in string:\n",
    "        if ((c > 'A') and (c < 'z')):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "finished-aluminum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative language detector --- based on UTF-8, if contain any character outside this range, considered as foreign language\n",
    "def check_non_eng(string):\n",
    "    for char in string:\n",
    "        if char < '~':\n",
    "            return False\n",
    "    return True\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "relative-sociology",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove reviews that doesnot contain alphabetic letter for langdetect module\n",
    "'''\n",
    "raw_df['letter'] = raw_df['review'].apply(lambda x: check_letter(x))\n",
    "            \n",
    "# Filter out reviews that contains only emoji (no letter)\n",
    "#print(raw_df[raw_df.letter == False])\n",
    "\n",
    "raw_df = raw_df[raw_df.letter == True]\n",
    "raw_df['lang'] = raw_df['review'].apply(detect)\n",
    "raw_df[raw_df.lang != 'en']\n",
    "\n",
    "\n",
    "raw_df_en = raw_df[raw_df.lang == 'en']\n",
    "\n",
    "#raw_df.head(10)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "existing-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization\n",
    "def preprocess_text(text,  flg_lemm=True):\n",
    "    ## clean (convert to lowercase and remove punctuations and characters and then strip)\n",
    "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
    "            \n",
    "    ## Tokenize (convert from string to list)\n",
    "    lst_text = text.split()\n",
    "                \n",
    "    ## Lemmatisation (convert the word into root word)\n",
    "    if flg_lemm == True:\n",
    "        lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "        lst_text = [lem.lemmatize(word) for word in lst_text]\n",
    "            \n",
    "    ## back to string from list\n",
    "    text = \" \".join(lst_text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-coffee",
   "metadata": {},
   "source": [
    "#### Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "transparent-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split train test set\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(raw_df.review, raw_df.label, test_size=0.2, random_state=RandomState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-messenger",
   "metadata": {},
   "source": [
    "#### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efficient-dealer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize datasets using Word2vec -- TFIDF\n",
    "  # input processed datasets and return vectorized datasets\n",
    "def get_vect(X_train, X_test, StopWords='english',MinDf=500,Ngram =(1,2), add_ft=False):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(stop_words=StopWords,min_df=MinDf,ngram_range=Ngram)\n",
    "    X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "    X_test_vectorized = vectorizer.transform(X_test)\n",
    "    \n",
    "    # Adding Polariry as feature (using TextBlob)\n",
    "    if add_ft == True:\n",
    "        X_pol_train = X_train.apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "        X_pol_test = X_test.apply(lambda x: TextBlob(x).sentiment.polarity)\n",
    "        X_train_vectorized = np.concatenate((X_train_vectorized.toarray(), X_pol_train.to_numpy().reshape((-1, 1))), axis=1)\n",
    "        X_test_vectorized = np.concatenate((X_test_vectorized.toarray(), X_pol_test.to_numpy().reshape((-1, 1))), axis=1)\n",
    "          \n",
    "        \n",
    "    return X_train_vectorized, X_test_vectorized\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fluid-bahamas",
   "metadata": {},
   "source": [
    "## Model building and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "seven-height",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model and return f1 score and accuracy of specified model\n",
    "  #input vectorized datasets and model tuning parameter, output f1 \n",
    "def get_perform(classifier, X_train, y_train, X_test, y_test, MaxDepth=None, MaxFeatures='auto',C_para=1.0):\n",
    "    if classifier == 'RandomForest':\n",
    "        clf = RandomForestClassifier(random_state=RandomState,max_features=MaxFeatures,max_depth=MaxDepth)\n",
    "    elif classifier == 'DecisionTree':\n",
    "        clf = DecisionTreeClassifier(random_state=RandomState,max_features=MaxFeatures,max_depth=MaxDepth)\n",
    "    elif classifier == 'SVC':\n",
    "        clf = SVC(C=C_para,random_state=RandomState)\n",
    "    elif classifier == 'Dummy':\n",
    "        clf = DummyClassifier(strategy=\"uniform\", random_state=RandomState)        \n",
    "    else:\n",
    "        print('Unexpected model type')\n",
    "    clf.fit(X_train, y_train)\n",
    "    preds = clf.predict(X_test)\n",
    "    f1 = f1_score(y_test, preds, pos_label='positive',average='binary')\n",
    "\n",
    "    return f1\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "injured-gasoline",
   "metadata": {},
   "source": [
    "### Compare performace with differenct models\n",
    "#### Raw data without preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adaptive-invalid",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_models = ['RandomForest', 'DecisionTree','SVC', 'Dummy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "blank-julian",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of each model for un-processed data \n",
      "\n",
      "RandomForest  classifier  \n",
      " f1 score:  0.7632232871849486\n",
      "DecisionTree  classifier  \n",
      " f1 score:  0.6941534302129097\n",
      "SVC  classifier  \n",
      " f1 score:  0.7734650670430486\n",
      "Dummy  classifier  \n",
      " f1 score:  0.5396600566572237\n"
     ]
    }
   ],
   "source": [
    "# Raw data with raw model --- no parameter tuned\n",
    "X_train_raw, X_test_raw = get_vect(X_train, X_test, StopWords=None,MinDf=500,Ngram =(1,2), add_ft=False)\n",
    "print('Performance of each model for un-processed data \\n', )\n",
    "for classifier in clf_models:\n",
    "    f1_score_raw = get_perform(classifier, X_train_raw, y_train, X_test_raw, y_test,MaxDepth=None, MaxFeatures='auto',C_para=1.0)\n",
    "    print(classifier,' classifier  \\n f1 score: ', f1_score_raw, )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arranged-midwest",
   "metadata": {},
   "source": [
    "#### Apply lemmatization only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cloudy-patrick",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of each model for lemmatized only data \n",
      "\n",
      "RandomForest  classifier  \n",
      " f1 score:  0.766928011404134\n",
      "DecisionTree  classifier  \n",
      " f1 score:  0.6983695652173914\n",
      "SVC  classifier  \n",
      " f1 score:  0.7778165329612836\n",
      "Dummy  classifier  \n",
      " f1 score:  0.5396600566572237\n"
     ]
    }
   ],
   "source": [
    "# Lemmatized text only\n",
    "\n",
    "X_train_lem = X_train.apply(lambda x: preprocess_text(x))\n",
    "X_test_lem = X_test.apply(lambda x: preprocess_text(x))\n",
    "\n",
    "X_train_lem_vec, X_test_lem_vec = get_vect(X_train_lem, X_test_lem, StopWords=None,MinDf=500,Ngram =(1,2), add_ft=False)\n",
    "\n",
    "\n",
    "print('Performance of each model for lemmatized only data \\n', )\n",
    "for classifier in clf_models:\n",
    "    f1_score_lem_vec = get_perform(classifier, X_train_lem_vec, y_train, X_test_lem_vec, y_test, MaxDepth=None, MaxFeatures='auto',C_para=1.0)\n",
    "    print(classifier,' classifier  \\n f1 score: ', f1_score_lem_vec )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "closed-support",
   "metadata": {},
   "source": [
    "#### Apply lemmatization and stopwords removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "natural-amendment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of each model for lemmatized data and stopwords removal\n",
      "\n",
      "RandomForest  classifier  \n",
      " f1 score:  0.7392455327597618\n",
      "DecisionTree  classifier  \n",
      " f1 score:  0.7227912932138284\n",
      "SVC  classifier  \n",
      " f1 score:  0.7368071689346165\n",
      "Dummy  classifier  \n",
      " f1 score:  0.5396600566572237\n"
     ]
    }
   ],
   "source": [
    "# Lemmatized text with stopwords removal\n",
    "\n",
    "X_train_lem_re = X_train.apply(lambda x: preprocess_text(x))#, lst_stopwords))\n",
    "X_test_lem_re = X_test.apply(lambda x: preprocess_text(x))\n",
    "\n",
    "X_train_lem_re_vec, X_test_lem_re_vec = get_vect(X_train_lem_re, X_test_lem_re, StopWords='english',MinDf=500,Ngram =(1,2), add_ft=False)\n",
    "print('Performance of each model for lemmatized data and stopwords removal\\n', )\n",
    "for classifier in clf_models:\n",
    "    f1_score_lem_re_vec = get_perform(classifier, X_train_lem_re_vec, y_train, X_test_lem_re_vec, y_test, MaxDepth=None, MaxFeatures='auto',C_para=1.0)\n",
    "    print(classifier,' classifier  \\n f1 score: ', f1_score_lem_re_vec )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "homeless-baseball",
   "metadata": {},
   "source": [
    "We can see that these is no significant improvement with lemmatization and stopwords removal. \n",
    "\n",
    "#### Apply language detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "rotary-shannon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>label</th>\n",
       "      <th>non_en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>ğŸ˜©</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>835</th>\n",
       "      <td>ğŸ¤¢ğŸ¤®</td>\n",
       "      <td>1</td>\n",
       "      <td>negative</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>ğŸ‘ğŸ‘ğŸ‘</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>ğŸ‘ğŸ¼ğŸ‘ğŸ¼ğŸ‘ğŸ¼</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>ğŸ˜ğŸ§ğŸ¤£ğŸ¤“</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>è®Šå¾ˆè²´ã€‚</td>\n",
       "      <td>3</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>æ–¹ä¾¿å¿«æ·çœé’±ã€‚ä¸èµ¶æ—¶é—´åšæ‹¼è½¦å¾ˆåˆ’ç®—</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>æ›´æ–°çš„ç‰ˆæœ¬è¿˜æ²¡å°è¯•ï¼Œä¹‹å‰çš„é‚£ä¸ªæœ‰æ—¶å®šä½ä¸å‡†ï¼Œé€ æˆè¿‡ä¸¤æ¬¡éº»çƒ¦ã€‚</td>\n",
       "      <td>4</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>961</th>\n",
       "      <td>æ­è½¦ä¾¿å®œå¤šäº†ï¼Œå¸Œæœ›èƒ½å¤Ÿä¸€ç›´è¿™æ ·</td>\n",
       "      <td>5</td>\n",
       "      <td>positive</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             review  rating     label  non_en\n",
       "773                               ğŸ˜©       1  negative    True\n",
       "835                              ğŸ¤¢ğŸ¤®       1  negative    True\n",
       "840                             ğŸ‘ğŸ‘ğŸ‘       5  positive    True\n",
       "845                          ğŸ‘ğŸ¼ğŸ‘ğŸ¼ğŸ‘ğŸ¼       5  positive    True\n",
       "856                          ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘ğŸ‘       5  positive    True\n",
       "857                            ğŸ˜ğŸ§ğŸ¤£ğŸ¤“       5  positive    True\n",
       "858                            è®Šå¾ˆè²´ã€‚       3  positive    True\n",
       "920               æ–¹ä¾¿å¿«æ·çœé’±ã€‚ä¸èµ¶æ—¶é—´åšæ‹¼è½¦å¾ˆåˆ’ç®—       5  positive    True\n",
       "927  æ›´æ–°çš„ç‰ˆæœ¬è¿˜æ²¡å°è¯•ï¼Œä¹‹å‰çš„é‚£ä¸ªæœ‰æ—¶å®šä½ä¸å‡†ï¼Œé€ æˆè¿‡ä¸¤æ¬¡éº»çƒ¦ã€‚       4  positive    True\n",
       "961                 æ­è½¦ä¾¿å®œå¤šäº†ï¼Œå¸Œæœ›èƒ½å¤Ÿä¸€ç›´è¿™æ ·       5  positive    True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['non_en'] = raw_df['review'].apply(lambda x: check_non_eng(x))\n",
    "\n",
    "raw_df[raw_df.non_en == True].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "protected-forestry",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_df = raw_df[raw_df.non_en == False]\n",
    "\n",
    "X_train_en, X_test_en, y_train_en, y_test_en = train_test_split(en_df.review, en_df.label, test_size=0.2, random_state=RandomState)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "clean-spank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of each model for English-only data \n",
      "\n",
      "RandomForest  classifier  \n",
      " f1 score:  0.7883315546069014\n",
      "DecisionTree  classifier  \n",
      " f1 score:  0.705761316872428\n",
      "SVC  classifier  \n",
      " f1 score:  0.8034965034965035\n",
      "Dummy  classifier  \n",
      " f1 score:  0.5198711063372718\n"
     ]
    }
   ],
   "source": [
    "# Language detection\n",
    "\n",
    "X_train_lem_en = X_train_en.apply(lambda x: preprocess_text(x))\n",
    "X_test_lem_en = X_test_en.apply(lambda x: preprocess_text(x))\n",
    "\n",
    "\n",
    "X_train_lem_en_vec, X_test_lem_en_vec = get_vect(X_train_lem_en, X_test_lem_en, StopWords=None,MinDf=500,Ngram =(1,2), add_ft=False)\n",
    "print('Performance of each model for English-only data \\n', )\n",
    "for classifier in clf_models:\n",
    "    f1_score_lem_en = get_perform(classifier, X_train_lem_en_vec, y_train_en, X_test_lem_en_vec, y_test_en, MaxDepth=None, MaxFeatures='auto',C_para=1.0)\n",
    "    print(classifier,' classifier  \\n f1 score: ', f1_score_lem_en )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worth-miracle",
   "metadata": {},
   "source": [
    "There is slight improvement after we filter out reviews in other languages. \n",
    "\n",
    "#### Add polarity as feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "based-claim",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of each model after adding polarity as feature \n",
      "\n",
      "RandomForest  classifier  \n",
      " f1 score:  0.8063241106719368\n",
      "DecisionTree  classifier  \n",
      " f1 score:  0.7446736557321609\n",
      "SVC  classifier  \n",
      " f1 score:  0.8236963462220646\n",
      "Dummy  classifier  \n",
      " f1 score:  0.5198711063372718\n"
     ]
    }
   ],
   "source": [
    "X_train_pol_vec, X_test_pol_vec = get_vect(X_train_lem_en, X_test_lem_en, StopWords=None,MinDf=500,Ngram =(1,2), add_ft=True)\n",
    "print('Performance of each model after adding polarity as feature \\n', )\n",
    "for classifier in clf_models:\n",
    "    f1_score_pol = get_perform(classifier, X_train_pol_vec, y_train_en, X_test_pol_vec, y_test_en, MaxDepth=None, MaxFeatures='auto',C_para=1.0)\n",
    "    print(classifier,' classifier  \\n f1 score: ', f1_score_pol )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-candidate",
   "metadata": {},
   "source": [
    "Adding polarity as feature does boost the performance. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
